{"meta":{"title":"天外飞猪的博客","subtitle":null,"description":"人为什么越长大越孤单？\n答:内心中有秘密,无法诉说\n","author":"fbZhu","url":"http://yoursite.com"},"pages":[{"title":"tags","date":"2018-04-04T07:35:47.000Z","updated":"2018-04-04T07:44:50.377Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"kafka消息","slug":"kafka消息","date":"2018-04-11T05:39:08.000Z","updated":"2018-04-11T05:43:20.583Z","comments":true,"path":"2018/04/11/kafka消息/","link":"","permalink":"http://yoursite.com/2018/04/11/kafka消息/","excerpt":"","text":"带着以下两点疑问，进行kafka server的Log管理源码的分析： producer遇到 NOT_LEADER_EXCEPTION 是在何时产生的 消息是如何在ISR中备份的 下面以从上往下的方式对一条消息写入磁盘的全链路进行分析 KafkaApis kafka apis反映出kafka broker server可以提供哪些服务，broker server主要和producer，consumer，controller有交互，搞清这些api就清楚了broker server的所有行为 handleProducerRequest 该方法用于处理Client的producer请求，ApiKeys = 0 从 RequestChannel 中获取请求，然后根据acks规则进行反馈 写入磁盘的动作在replicaManager.appendRecords中完成 ack规则 acks 规则 0 producer不需要等待ack,server收到消息后直接反馈 1 leader成功写入后反馈给producer -1 (kafka-client中配置为&quot;all&quot;) 在ISR中所有replicas都写入消息后才进行反馈 ReplicaManager.appendMessages 先将消息写入leader的log中(正常情况就是当前这个broker) 将消息写到ISR的其他备份中 超时或者ack规则满足时进行反馈操作(执行回调函数：responseCallback) //写到leader的logval localProduceResults = appendToLocalLog(internalTopicsAllowed, entriesPerPartition, requiredAcks)if (delayedRequestRequired(requiredAcks, entriesPerPartition, localProduceResults)) &#123;//acks=-1时需要创建 delayedProduce实现消息的备份val produceMetadata = ProduceMetadata(requiredAcks, produceStatus)val delayedProduce = new DelayedProduce(timeout, produceMetadata, this, responseCallback)val producerRequestKeys = entriesPerPartition.keys.map(new TopicPartitionOperationKey(_)).toSeqdelayedProducePurgatory.tryCompleteElseWatch(delayedProduce, producerRequestKeys)&#125; else &#123;val produceResponseStatus = produceStatus.mapValues(status =&gt; status.responseStatus)responseCallback(produceResponseStatus)&#125; ReplicaManager.appendToLocalLog 当topic为内部topic(即__consumer_offsets)，并且不允许往内部类中写消息时，抛出 InvalidTopicException val info = partitionOpt match &#123; case Some(partition) =&gt; partition.appendRecordsToLeader(records, requiredAcks) case None =&gt; throw new UnknownTopicOrPartitionException(&quot;Partition %s doesn&apos;t exist on %d&quot; .format(topicPartition, localBrokerId))&#125; Partition.appendRecordsToLeader判断当前broker是否是parition的leaderdef getReplica(replicaId: Int = localBrokerId): Option[Replica] = Option(assignedReplicaMap.get(replicaId))def leaderReplicaIfLocal: Option[Replica] = leaderReplicaIdOpt.filter(_ == localBrokerId).flatMap(getReplica) assignedReplicaMap：用于存放每个partition对应的leader已经replicas 通过比较leaderId与localBrokerId，判断当前broker是否就是leader 如果不满足，那么将抛出NotLeaderForPartitionException 备份数不满足条件的消息不会写入 val log = leaderReplica.log.get val minIsr = log.config.minInSyncReplicas val inSyncSize = inSyncReplicas.size// acks为all的时候才会进行判断 if (inSyncSize &lt; minIsr &amp;&amp; requiredAcks == -1) &#123; throw new NotEnoughReplicasException(&quot;Number of insync replicas for partition %s is [%d], below required minimum [%d]&quot; .format(topicPartition, inSyncSize, minIsr)) &#125; Log.append 返回的格式为LogAppendInfo,包含第一条及最后一条offset信息 找到该Partition在当前broker上面最新的segment，如果塞不进去 就新建一个segment 将消息添加到segment中 更新segment的LogEndOffset为最新添加消息的lastOffset + 1ByteBufferMessageSetappend方法中传入的消息集的数据结构为ByteBufferMessageSet (注：在0.10.2.0版本后引入新的结构：MemoryRecords)，父类为Messageset,其结构如下图所示： 一个有效的MessageSet的最小长度为12字节 Message的组成Message在magic不同的情况下有不同的结构：迭代器的实现internalIterator是ByteBufferMessageSet实现的迭代器，迭代单位是MessageAndOffset magic的值是由server中Log的配置属性：message.format.version决定的，0.10.0之前的版本的magic值为0，之后的版本为1 迭代的过程也是对消息的有效性的检验过程： ByteBuffer(对应MessageSet)的长度是否&lt; 12 消息体(对应Message)的长度是否 &lt; 魔术为0时Message的头部长度(4+1+1+8+4 = 18) ByteBuffer的长度是否&lt;消息体的长度(否则就表明消息不完整) 满足以上条件的消息一定是无法继续迭代的 由于消息的载体实现的是ByteBuffer，那我们就从Buffer的操作的角度来看看message和offset是如何被迭代取出来的： 假设当前接收到一个新的ByteBuffer，下面进行迭代： 获取buffer的片段(第一次算是拷贝)：topIter = buffer.slice() 获取offset(获取前八个字节)： offset = topIter.getLong() 获取size(获取紧接着的四个字节)：size = topIter.getInt() 获取message(当前position指向message的开始位置，截取后续size大小的就可以得到message)：message = topIter.slice; message.limit(size) 将topIter的position指向下一条MessageSet: topIter.position(topIter.position + size) LogAppendInfo的生成LogAppendInfo主要包含四个属性，用于描述message set: firstOffest：第一条消息的offset: lastOffset：最后一条消息的offset: maxTimestamp：消息里面包含的最大时间戳: offsetOfMaxTimestamp：最大时间戳消息的offset analyzeAndValidateMessageSet方法实现了LogAppendInfo的生成，根据上面提到的迭代器对MessageSet中的消息进行迭代处理，找出并记录offset和timestamp信息，此外也对每条消息进行检验： 每条消息的大小不能超过max.message.bytes所定义的 每条消息必须通过循环冗余校验 消息的进一步校验对消息的进一步校验及转化是在validateMessagesAndAssignOffsets方法中完成的。该方法的参数中涉及到一些概念： 1.topic清理策略log.cleanup.policy配置项控制着消息在segment中持久化的策略，目前有两种策略供选择：delete和compact，默认选项为delte。 delete的策略很好理解，就是当segment时间或者大小到期了就删除。 compact的策略是为了满足系统灾后恢复的需求，该选项是针对topic的，比如存在某个topic：email_topic用于存储用户变更的email信息，key=userId,value=emailAddress，compact操作就是在日志删除过程中保留每个userId最新的数据，如果系统崩溃了也能通过该topic获得用户最新修改的email地址。下面的图很好的诠释了这种操作： 2. 版本与magicValue 由于kafka的版本更新速度比较快，为了能让新的server版本兼容老的client版本以及server的滚动升级的实现，提供了message.format.version配置项定义consumer及Producer的API版本。 不同的API版本对应不同的magicValue，其中0.9.0.X版本之前(包括该版本)的magicValue未0，之后的都为1 当前我们生产环境使用的API版本为0.10.0.0，server的版本为0.10.1.1 3. 解析非压缩消息 producer可以选择是否对消息进行压缩 message.timestamp.type：时间戳类型: CreateTime：消息的创建时间&lt;默认值&gt;: LogAppendTime：添加到log的时间 message.timestamp.difference.max.ms：最大时间间隔,表示收到的消息中的时间戳与当前时间的差的最大容忍值。 对非压缩消息的进一步处理的过程依然是ByteBuffer的操作过程：/*主要目的是获取maxTimestamp和offsetOfMaxTimestamp*/var messagePosition = 0var maxTimestamp = Message.NoTimestampvar offsetOfMaxTimestamp = -1L//将position位置存到mark中buffer.mark()while (messagePosition &lt; sizeInBytes - MessageSet.LogOverhead) &#123; buffer.position(messagePosition) //offsetCounter是server维护的下一个offset的值 buffer.putLong(offsetCounter.getAndIncrement()) val messageSize = buffer.getInt() val messageBuffer = buffer.slice() messageBuffer.limit(messageSize) val message = new Message(messageBuffer) //以上的操作能获取到MessageSet中的一条message if (message.magic &gt; Message.MagicValue_V0) &#123; validateTimestamp(message, now, timestampType, timestampDiffMaxMs) if (message.timestamp &gt; maxTimestamp) &#123; maxTimestamp = message.timestamp offsetOfMaxTimestamp = offsetCounter.value - 1 &#125; &#125; //将buffer的position移到后一条消息的头部 messagePosition += MessageSet.LogOverhead + messageSize&#125;//根据mark恢复positionbuffer.reset() 经过上面的操作，MessageSet中的offset被server重新设置了，并且maxTimestamp之类的信息重新收集了。这些信息在append操作中会被使用：validMessages = validateAndOffsetAssignResult.validatedMessagesappendInfo.maxTimestamp = validateAndOffsetAssignResult.maxTimestampappendInfo.offsetOfMaxTimestamp = validateAndOffsetAssignResult.offsetOfMaxTimestampappendInfo.lastOffset = offset.value - 1 其中：: validMessages就是处理完后的MessageSet: offset是上面使用到的offsetCounter，即下一个offset值。为什么要-1?因为上面执行了getAndIncrement()操作，因此当前的offset指向的依然是下一个offset值 4.压缩消息的处理 producer的压缩策略必须与broker一致，如果不匹配那么将不会解压缩消息 以下几种情况不会对压缩消息进行解压处理： topic指定了压缩策略，但是发送的消息中没有key(会报错) 消息体与server的magic值不一致 找到合适的segment 一个topic由多个parition组成，每个partition又存在多个segment 每个segment的大小由log.segment.bytes控制,下面是segment大小设置为1024的broker上某个partiton的Log情况：[test-0]$ du -smh *0 00000000000000017699.index4.0K 00000000000000017699.log4.0K 00000000000000017699.timeindex0 00000000000000017724.index4.0K 00000000000000017724.log0 00000000000000017724.timeindex 每个log的命名规则是取该log中 下一个 offset的值(logEndOffset); 以index结尾的offset index文件的作用是将offset映射到物理文件中 timeindex文件将时间戳与segment中的逻辑offset联系起来 满足以下几个条件之一时会创建新的segment： 当前segment容不下最新的消息 当前segment非空，并且达到了log.roll.hours的时间 offset 或者 time index满了 下面是写消息时创建出新的segment时server的输出日志：[2017-04-05 17:14:29,776] DEBUG Rolling new log segment in test-11 (log_size = 1006/1024&#125;, index_size = 0/1310720, time_index_size = 1/873813, inactive_time_ms = 184193/604800000). (kafka.log.Log) 将消息添加到LogSegment中LogSegment的参数主要有：: log：File类型的MessageSet，该Set中包含一个FileChannel，能够从ByteBuffer中读取数据: index: OffsetIndex，逻辑Offset到物理文件位置的索引: timeIndex：TimeIndex，时间戳到物理位置的索引: baseOffset：第一个offset 写消息的操作：将AppendInfo中的消息写入到LogSegment中的FileChannel中def writeFullyTo(channel: GatheringByteChannel): Int = &#123; buffer.mark() var written = 0 while (written &lt; sizeInBytes) written += channel.write(buffer) buffer.reset() written&#125; _size.getAndAdd(written) FileMessageSet的search操作根据offset或者时间戳是从Log中读取消息的常见方法。FileMessageSet提供对应的两个方法：searchForOffsetWithSize和searchForTimestamp。前者是从FileMessageSet的给定位置往后搜索第一个大于等于目标offset的消息，返回的是Offset&amp;Position，后者是从给定位置往后搜索第一个时间戳大于等于目标时间戳的消息，返回Timestamp&amp;Offset。 下图描述的是从0开始搜索offset≥1003的消息： 写OffsetIndexOffsetIndex中并不会记录所有Offset的映射关系，写入Index的时机由index.interval.bytes参数(default：4096)控制，当segment中积累的消息数量大于该参数时，会将此次写入segment中的MessageSet的第一个消息的offset写入OffsetIndex中：if(bytesSinceLastIndexEntry &gt; indexIntervalBytes) &#123; index.append(firstOffset, physicalPosition) timeIndex.maybeAppend(maxTimestampSoFar, offsetOfMaxTimestamp) bytesSinceLastIndexEntry = 0&#125;bytesSinceLastIndexEntry += messages.sizeInBytes index.append的具体操作如下：if (_entries == 0 || offset &gt; _lastOffset) &#123; mmap.putInt((offset - baseOffset).toInt) mmap.putInt(position) _entries += 1 _lastOffset = offset&#125; 上面的操作是将offset相对这个Segmet的baseOffset的偏移值以及物理地址填入到OffsetIndex中定义的MappedByteBuffer。 之所以使用相对偏移值是出于节省存储空间的考虑，相对偏移值只需要4位空间就能存储，而MessageSet中的offset占8位。 写TimeIndex在每次执行append操作时，TimeIndex记录的是最大时间戳及其对应的offset的索引。if (timestamp &gt; lastEntry.timestamp) &#123; mmap.putLong(timestamp) mmap.putInt((offset - baseOffset).toInt) _entries += 1&#125; 写入Buffer中的是时间戳以及相对偏移量 更新LogEndOffset上面的分析中提到过每个Log都维护了一个记录下一个offset的变量——nextOffsetMetadata,该变量是LogOffsetMetadata类型的：: messageOffset：绝对偏移值: segmentBaseOffset：LogSegment的baseOffset值: relativePositionInSegment：LogSegment的大小(字节数)，根据字节数可以定位到这条消息在segment中的物理位置 每次append操作都会执行：nextOffsetMetadata = new LogOffsetMetadata(messageOffset, activeSegment.baseOffset, activeSegment.size.toInt)其中： messageOffset为 AppendInfo.lastOffset+1 activeSegment是当前可用的segment activeSegment.size由_size.get()，这个_size正是在上面往segment中写消息时进行更新的，每次增加的值是写入channel中的字节数。 下面这张图生动描述了这个更新的操作： 绿色的代表activeSegment，当前的nextOffsetMetadata为10(指的是messageOffset) 写入10条消息后，nextOffsetMetadata更新为21 再次写入10条消息后，更新为31 再来10条消息，无法写入，执行roll操作新建一个segment,messageOffset值未改变，不过activeSegment变化了 将10条消息写入新的segment中，更新为41","categories":[],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"Kafka Coordinator实现细节","slug":"Kafka-Coordinator实现细节","date":"2018-04-04T07:29:55.000Z","updated":"2018-04-04T07:44:07.656Z","comments":true,"path":"2018/04/04/Kafka-Coordinator实现细节/","link":"","permalink":"http://yoursite.com/2018/04/04/Kafka-Coordinator实现细节/","excerpt":"","text":"GroupCoordinator 每个kafka server在启动的时候会创建一个GroupCoordinator用于管理group以及consumer的offset fetch/commit 在创建GroupCoordinator实例时不仅需要brokerId、group以及offset config，还需要传入replicaManager，其作用是 GroupMetadataManagerGroupMetadataManager是GroupCoordinator最重要的组成部分，其作用是管理group的元信息(状态、成员、提交的offset信息)以及作为coordinator的broker所分配到的分区信息，主要成员有4个： groupMetadataCache：存储group与GroupMetadata的cache loadingPartitions：”__consumer_offsets”中正在被当前coordinator加载的分区 ownedPartitions：”__consumer_offsets”中分配到当前coordinator的分区(即该broker是这些分区的leader) scheduler：删除过期offset以及group元数据的定时任务(执行间隔由offsets.retention.check.interval.ms参数控制，默认为10分钟) __consumer_offsets__consumer_offsets是用于存储消费者消费信息的topic，存储的消息由两部分组成 一部分是offset信息(kafka.coordinator.OffsetsMessageFormatter类型)的： [groupId,topic,partition]::[OffsetMetadata[offset,metadata],CommitTime ExprirationTime] 另一部分是group信息(kafka.coordinator.GroupMetadataMessageFormatter类型): groupId::[groupId,Some(consumer),groupState,Map(memberId -&gt; [memberId,clientId,clientHost,sessionTimeoutMs], ...-&gt;[]...)] group分配到哪个分区的策略在kafka cosumer中介绍过了。 作为一个特殊的topic，consumer_offsets也有replica的概念，并且其replica factor与其他topic保持一致。consumer_offsets上每个分区都对应一个leader，作为leader的broker上的GroupCoordinator会记录着分区上记录着的group以及offset信息。当leader(__consumer_offsets分布的leader)发生变化时，新的leader需要加载对应分区上的group以及offset信息。 server在处理LeaderAndIsrRequest时会对__consumer_offsets的分区做出入境 操作：def onLeadershipChange(updatedLeaders: Iterable[Partition], updatedFollowers: Iterable[Partition]) &#123; updatedLeaders.foreach &#123; partition =&gt; if (partition.topic == Topic.GroupMetadataTopicName) coordinator.handleGroupImmigration(partition.partitionId) &#125; updatedFollowers.foreach &#123; partition =&gt; if (partition.topic == Topic.GroupMetadataTopicName) coordinator.handleGroupEmigration(partition.partitionId) &#125;&#125; 小实验“G3”这个group根据hash映射到分区2上，当前的ISR为：Topic: __consumer_offsets Partition: 2 Leader: 1 Replicas: 1,3,2 Isr: 2,3,1 接下来，关闭broker1，导致broker3成为了新的leader。 broker3执行入境 操作，加载分区2上面的的offset以及group信息：[Group Metadata Manager]: Loading offsets and group metadata from [__consumer_offsets,2][Group Metadata Manager]: Loaded group metadata for group G3 with generation 1[Group Metadata Manager]: Loaded group metadata for group G3 with generation 2[Group Metadata Manager]: Loaded group metadata for group G3 with generation 3[Group Metadata Manager]: Loaded group metadata for group G3 with generation 4[Group Metadata Manager]: Loaded offset [OffsetMetadata[3448,NO_METADATA],CommitTime 1495503059311,ExpirationTime 1495506659311] for newOne-0.[Group Metadata Manager]: Loaded offset [OffsetMetadata[3441,NO_METADATA],CommitTime 1495503059311,ExpirationTime 1495506659311] for newOne-3.[Group Metadata Manager]: Loaded offset [OffsetMetadata[3257,NO_METADATA],CommitTime 1495503059311,ExpirationTime 1495506659311] for newOne-5.[Group Metadata Manager]: Loaded offset [OffsetMetadata[3382,NO_METADATA],CommitTime 1495503059311,ExpirationTime 1495506659311] for newOne-2.[Group Metadata Manager]: Loaded offset [OffsetMetadata[3397,NO_METADATA],CommitTime 1495503059311,ExpirationTime 1495506659311] for newOne-4.[Group Metadata Manager]: Loaded offset [OffsetMetadata[3163,NO_METADATA],CommitTime 1495503059311,ExpirationTime 1495506659311] for newOne-1.[GroupCoordinator 3]: Loading group metadata for G3 with generation 4[Group Metadata Manager]: Finished loading offsets from [__consumer_offsets,2] in 21 milliseconds. 在loadGroupsForPartition方法中通过使用Map确保加载每个group最新generation的信息 在执行入境操作之前，分区2被添加到loadingPartitions中，表示coordinator正在加载该分区里面的信息，这个阶段如果有groupId在loadingPartitions之内的消费请求进来，是无法响应的；处理完后，分区2被添加到ownedPartitions中。 保存group元数据方法定义如下：def prepareStoreGroup(group: GroupMetadata, groupAssignment: Map[String, Array[Byte]], responseCallback: Errors =&gt; Unit): Option[DelayedStore] groupAssignment是group中member的分区分配 返回值是DelayedStore，这并不是一个DO类型的延迟任务，只适用于存放消息的临时媒介，方便后续往replicas中写Log用的。 生成消息第一步是生成能往Log(确切的说是写入__consumer_offsets中该group对应的partition中)中写入的ByteBufferMessageSet(消息写入磁盘及备份实现分析),key为groupId,value为member以及sessionTimeout，即上面所说的group信息。 设置appendLog回调函数该回调函数作为参数传入到ReplicaManager.replicaMessages，对append操作的结果进行处理，最主要的就是状态的转换：case Errors.UNKNOWN_TOPIC_OR_PARTITION | Errors.NOT_ENOUGH_REPLICAS | Errors.NOT_ENOUGH_REPLICAS_AFTER_APPEND =&gt; Errors.GROUP_COORDINATOR_NOT_AVAILABLEcase Errors.NOT_LEADER_FOR_PARTITION =&gt; Errors.NOT_COORDINATOR_FOR_GROUPcase Errors.REQUEST_TIMED_OUT =&gt; Errors.REBALANCE_IN_PROGRESScase Errors.MESSAGE_TOO_LARGE | Errors.RECORD_LIST_TOO_LARGE | Errors.INVALID_FETCH_SIZE =&gt; Errors.UNKNOWN 执行storeGroup回调函数在doSyncGroup中定义了一个用于处理leader的SyncGroupRequest的回调函数：group synchronized &#123; if (group.is(AwaitingSync) &amp;&amp; generationId == group.generationId) &#123; if (error != Errors.NONE) &#123; resetAndPropagateAssignmentError(group, error) maybePrepareRebalance(group) &#125; else &#123; setAndPropagateAssignment(group, assignment) group.transitionTo(Stable) &#125; &#125;&#125; 因为在等待回调函数被执行的过程中，可能会有新的member加入，这样的话就无法保证group的状态以及generation不会变化的。 往replicas写group数据调用GroupMetadataManager的store方法，将DelayedStore中的messageSet以及回调函数传入到replicaManager的appendMessages方法中replicaManager.appendMessages( config.offsetCommitTimeoutMs.toLong, config.offsetCommitRequiredAcks, true, // allow appending to internal offset topic delayedStore.messageSet, delayedStore.callback) 保存offset commitprepareStoreOffsets方法与prepareStoreGroup基本相像：def prepareStoreOffsets(group: GroupMetadata, consumerId: String, generationId: Int, offsetMetadata: immutable.Map[TopicPartition, OffsetAndMetadata], responseCallback: immutable.Map[TopicPartition, Short] =&gt; Unit): Option[DelayedStore] 返回的依然是个DelayedStore。组装的MessageSet中,key为[groupId, topic, partition]，value为OffsetMetadata，写入的partition由groupId确定。 offsetCommit回调函数 GroupMetadata为offset commit创建了两个Cache：offsets以及pendingOffsetCommits，consumer提交的offset先存放到pending中，然后根据一定的状态来决定是否移到offsets中。 如果offsetCommit执行结束后group依旧存活那个根据是否有错误对cache执行不同的操作： 没有错误码，那么就将offset写入到offsets中，并从pendingOffsetCommits中移除； 有错误，那么仅仅将offset从pendingOffsetCommits中移除； offset以及group元数据的清理工作GroupMetadataManager在启动时会开启一个定时执行的清理线程：”delete-expired-group-metadata”，该线程的主要工作是清理__consumer_offsets中失效的offset以及可删除的group信息。 remove expire offset每个offset commit提交到server时，都会根据配置的保存时间来设置其失效时间，超过该时间的将会被清除掉。 首先，从cache中筛选出可清楚的offset集合：val expiredOffsets = offsets.filter &#123; case (topicPartition, offset) =&gt; offset.expireTimestamp &lt; startMs &amp;&amp; !pendingOffsetCommits.contains(topicPartition) &#125; offsets --= expiredOffsets.keySet expiredOffsets 执行完删除操作过后判断group是否可以判定为DEAD： group不包含member group的两个offsetCache都为空 立墓碑 当offset被移除或者group进入DEAD状态，都会在__consumer_offsets中留下一个墓碑。 对于group而言： 如果当前有member存在，那么其存在于__consumer_offsets中的数据是这样的： G6::[G6,Some(consumer),Stable,Map(client1-1ee1d482-c9fa-4617-860a-98d3a3d5a836 -&gt; [client1-1ee1d482-c9fa-4617-860a-98d3a3d5a836,client1,/10.45.48.129,120000])] 如果member为空，但是状态不是DEAD： G6::[G6,None,Empty,Map()] 如果group被该清理线程认为DEAD，该group信息不仅从groupMetadataCache中移除，还会在__cosnumer_offsets中留下一座墓碑： G6::NULL offset的立墓碑操作与group类似。 consumer与Coordinator的连接过程确定coordinator 在kafka cosumer中提到过consumer寻找coordinator的过程。 选择将哪个节点作为coordinator其实是由consumer client决定的，确切的说是向已连接的节点中随机选择一个最空闲的节点发送GroupCoordinatorRequest。(这里随机是指往一个空闲的随机broker发送请求，收到的response中分配到的coordinator是根据group找对__consumer_offsets对应分区的Leader)这里空闲的定义是：NetworkClient中处于inflight状态的请求数量少，下面是consumer寻找到coordinator的日志：[AbstractCoordinator] Sending coordinator request for group G6 to broker 10.45.4.10:9092[AbstractCoordinator] Received group coordinator response ClientResponse(receivedTimeMs=1495510047579, disconnected=false, request=ClientRequest(callback=..., request=RequestSend(header=&#123;api_key=10,api_version=0,correlation_id=0,client_id=client111&#125;, body=&#123;group_id=G6&#125;), createdTimeMs=1495510047472, sendTimeMs=1495510047577), responseBody=&#123;error_code=0,coordinator=&#123;node_id=1,host=10.45.4.9,port=9092&#125;&#125;) handleGroupCoordinatorRequestserver在接收到GroupCoordinatorRequest后： 根据groupId找到对应__consumer_offsets上的分区P 找到P对应的leader作为coordinator handleJoinGroup校验 简单校验： coordinator是否处于工作状态 groupId是否有效 coordinator是否负责该group sessionTimeoutMs是否合理 groupId是否在loadingPartitions中，如果在的话表明正在Rebalance中。 member校验：客户端ConsumerCoordinator发送的JoinGroupRequest 中的memberId永远都是空的，也就是说memberId是由server端进行设置的。如果Request中group是已知(存在于GroupMetadataManager.groupMetadataCache)的并且memberId非空，那么Server将拒绝这个请求。 响应请求 group有不同的状态，在不同的状态下有相应的响应joinGroupRequest方法 Deadgroup处于Dead状态表明该group中没有了成员，并且其GroupMetadata已被该coordinator移除,这个状态下对任何请求都是返回UnknownMemberIdException PreparingRebalance根据Request中memberId是否为空有两套处理逻辑： memberId为空：执行addMember操作 //新建memberId，格式为：clientId-UUID val memberId = clientId + &quot;-&quot; + group.generateMemberIdSuffixval member = new MemberMetadata(memberId, group.groupId, clientId, clientHost, rebalanceTimeoutMs, sessionTimeoutMs, protocolType, protocols)member.awaitingJoinCallback = callbackgroup.add(member.memberId, member)maybePrepareRebalance(group)member memberId不为空：执行updateMember操作 member.supportedProtocols = protocolsmember.awaitingJoinCallback = callbackmaybePrepareRebalance(group) 以上两个操作都不会触发PrepareRebalance操作，因为当前已经是PreparingReblance状态了。 AwaitingSync 这个状态表明coordinator已经发送了JoinGroupResponse了，正在等待leader发送分区分配的SyncGroupRequest. 这个时候如果收到一个memberId为空的JoinGroupRequest，表明group中有新的成员加入，除了要创建member信息添加到GroupMetadata中之外，还需要prepareRebalance，并将状态重新置为PreparingReblance 如果收到的memberId不为空，有两种情况： 该成员未收到之前发送过的JoinGroupResponse，这种情况就重新发送一个Response，leader和member分配不会改变的 这次的Request中改变了分区分配策略，因此需要执行updateMember操作，并且还需要执行PrepareRebalance操作将状态重新置为PreparingReblance。 Empty or Stable处理三种可能的joinGroup情形： 收到memberId为空的请求，group有新成员加入，执行addMember以及PrepareRebalce操作。 收到leader的joinGroup请求或者请求中的分配策略发生变化(何种场景下会leader会重发joinGroup请求嘞？分区变化时consumer是如何rejoin的) 其他情况(followers发送的没有内容变化的Join请求)说明followers可能没收到Response，因此重发Response。 handleSyncGroup在校验阶段如果发现该coordinator并不负责该group，则会反馈NotCoordinatorForGroupException。 能够正常响应SyncGroup请求的group状态为AwaitingSync和Stable，其中AwaitingSync状态下就是执行保存group数据 handleLeaveGroup主要有三步操作 1、从心跳DOP中移除心跳DOP(heartbeatPurgatory)中保存的是DelayedHeartbeat，该DO操作用于侦测member是否存活,成员变量包括group、member已经超时时间。当member要离开group时需要将该member对应的DO操作完成并移除掉。 2、从group中移除将member从其对应的GroupMetadata中的members中移除，然后根据当前group状态进行对应的处理： Stable or Empty：触发PrepareRebalance PreparingRebalance：complete掉joinPurgatory中该group的DJ操作 3、组装反馈信息其实consumer对LeaveGroupResponse不是很关心，因为不会重发。 handleFetchOffsetsconsumer是从coordinator维护的offset cache ：offsets中获取group已提交的offset信息的。 FetchRequest中包含group以及topic-partition信息，据此coordinator进行反馈： 如果group不存在 or group状态为DEAD，则返回的PartitionData中offset为-1(代表InvalidOffset) 如果未指定topic以及partition，那么就将offsets中所有的[topic-partition, commit offset]数据都反馈给consunmer 如果指定topic-partition，就将offsets中对应的数据反馈，找不到就反馈-1 Helper分区变化时consumer是如何rejoin的？消费者在长连接的时候，增加了分区的topic，client是如何感知到的呢，下面是实验过程记录： 10:33:08 开启consumer [AbstractCoordinator] Sending coordinator request for group G6 to broker 10.45.4.10:9092 (id: -2 rack: null)[AbstractCoordinator] Discovered coordinator 10.45.4.9:9092 (id: 2147483646 rack: null) for group G6.[ConsumerCoordinator] Revoking previously assigned partitions [] for group G6[ConcurrentMessageListenerContainer] partitions revoked:[][AbstractCoordinator] (Re-)joining group G6[AbstractCoordinator] Sending JoinGroup (&#123;group_id=G6,session_timeout=120000,member_id=,protocol_type=consumer,group_protocols=[&#123;protocol_name=range,protocol_metadata=java.nio.HeapByteBuffer[pos=0 lim=18 cap=18]&#125;]&#125;) to coordinator 10.45.4.9:9092 (id: 2147483646 rack: null)[AbstractCoordinator] Received successful join group response for group G6: [AbstractCoordinator] Successfully joined group G6 with generation 5[ConcurrentMessageListenerContainer] partitions assigned:[newOne-8, newOne-4, newOne-5, newOne-6, newOne-7, newOne-0, newOne-1, newOne-2, newOne-3] 10:34:17 controller检测到partitoin变化： [AddPartitionsListener on 2]: Partition modification triggered &#123;&quot;version&quot;:1,&quot;partitions&quot;:&#123;&quot;8&quot;:[2,1],&quot;4&quot;:[1,3],&quot;11&quot;:[2,1],&quot;9&quot;:[3,2],&quot;5&quot;:[2,1],&quot;10&quot;:[1,3],&quot;6&quot;:[3,2],&quot;1&quot;:[1,2],&quot;0&quot;:[3,1],&quot;2&quot;:[2,3],&quot;7&quot;:[1,3],&quot;3&quot;:[3,2]&#125;&#125; for path /brokers/topics/newOne (kafka.controller.PartitionStateMachine$PartitionModificationsListener) 10:38:10 client rejoin [ConsumerCoordinator] Revoking previously assigned partitions [newOne-8, newOne-4, newOne-5, newOne-6, newOne-7, newOne-0, newOne-1, newOne-2, newOne-3] for group G6[ConcurrentMessageListenerContainer] partitions revoked:[newOne-8, newOne-4, newOne-5, newOne-6, newOne-7, newOne-0, newOne-1, newOne-2, newOne-3][AbstractCoordinator] &quot;(Re-)joining group G6&quot;[AbstractCoordinator] Sending JoinGroup (&#123;group_id=G6,session_timeout=120000,member_id=client111-39aa3f5d-cdf2-492f-bf41-4affe1a00421,protocol_type=consumer,group_protocols=[&#123;protocol_name=range,protocol_metadata=java.nio.HeapByteBuffer[pos=0 lim=18 cap=18]&#125;]&#125;) to coordinator 10.45.4.9:9092 (id: 2147483646 rack: null)[AbstractCoordinator] Received successful join group response for group G6: &#123;error_code=0,generation_id=6,group_protocol=range,leader_id=client111-39aa3f5d-cdf2-492f-bf41-4affe1a00421,member_id=client111-39aa3f5d-cdf2-492f-bf41-4affe1a00421,members=[&#123;member_id=client111-39aa3f5d-cdf2-492f-bf41-4affe1a00421,member_metadata=java.nio.HeapByteBuffer[pos=0 lim=18 cap=18]&#125;]&#125;[AbstractCoordinator] Sending leader SyncGroup for group G6 to coordinator 10.45.4.9:9092 (id: 2147483646 rack: null): &#123;group_id=G6,generation_id=6,member_id=client111-39aa3f5d-cdf2-492f-bf41-4affe1a00421,group_assignment=[&#123;member_id=client111-39aa3f5d-cdf2-492f-bf41-4affe1a00421,member_assignment=java.nio.HeapByteBuffer[pos=0 lim=70 cap=70]&#125;]&#125;[AbstractCoordinator] Successfully joined group G6 with generation 6[ConsumerCoordinator] Setting newly assigned partitions [newOne-8, newOne-9, newOne-10, newOne-11, newOne-4, newOne-5, newOne-6, newOne-7, newOne-0, newOne-1, newOne-2, newOne-3] for group G6[ConcurrentMessageListenerContainer] partitions assigned:[newOne-8, newOne-9, newOne-10, newOne-11, newOne-4, newOne-5, newOne-6, newOne-7, newOne-0, newOne-1, newOne-2, newOne-3] 那么consumer到底是如何触发rejoin的呢，这个时间间隔有何讲究？ 一开始自己关注的点是rejoinNeeded什么时候被置为true 有三种情况下会被置为true： SyncGroupResponse中存在ERROR HeartbeatResponse中存在REBALANCE_IN_PROGRESS、ILLEGAL_GENERATION或UNKNOWN_MEMBER_ID的ERROR consumer leave group 然而从日志来看并没有出现错误，所以注意力转移到needRejoin方法中的其他判断条件：return subscriptions.partitionsAutoAssigned() &amp;&amp; (super.needRejoin() || subscriptions.partitionAssignmentNeeded()); partitionsAutoAssigned的条件是一直满足的，partitionAssignmentNeeded被置为true的场景有点多，排查起来比较费时费力。这时有个新的现象进入眼帘：经过多次试验后发现rejoin距离分区调整的时间间隔最长不超过5分钟！。而metadata.max.age.ms这个配置参数的默认值刚好是5分钟： 该配置项是client端强制刷新metadata的最长时间间隔。 因为kafka集群出现broker或者partition变化的时候是不会通知客户端的，因此客户端需要定期的去获取metadata的值。 客户端判断是否需要刷新metadata的方法：public synchronized long timeToNextUpdate(long nowMs) &#123; long timeToExpire = needUpdate ? 0 : Math.max(this.lastSuccessfulRefreshMs + this.metadataExpireMs - nowMs, 0); long timeToAllowUpdate = this.lastRefreshMs + this.refreshBackoffMs - nowMs; return Math.max(timeToExpire, timeToAllowUpdate);&#125; 其中metadataExpireMs就是5分钟【默认】。 ConsumerCoordinator为metadata添加了一个Listener监听其更新操作：private void addMetadataListener() &#123; this.metadata.addListener(new Metadata.Listener() &#123; @Override public void onMetadataUpdate(Cluster cluster) &#123; ... // check if there are any changes to the metadata which should trigger a rebalance if (subscriptions.partitionsAutoAssigned()) &#123; MetadataSnapshot snapshot = new MetadataSnapshot(subscriptions, cluster); if (!snapshot.equals(metadataSnapshot)) &#123; metadataSnapshot = snapshot; subscriptions.needReassignment(); &#125; &#125; &#125; &#125;);&#125; needReassignment()方法将needsPartitionAssignment置为true,这正是partitionAssignmentNeeded()方法所需要的。 how to prepare rebalance 在kafka cosumer中做个一个实验：consumer多次关闭重连后，partition将会在较长时间后才能分配到。GroupCoordinator做了什么才导致这样的现象发生嘞？ prepareReblance的代码不长，但是要搞懂到底做了些什么着实不易：private def prepareRebalance(group: GroupMetadata) &#123; // if any members are awaiting sync, cancel their request and have them rejoin if (group.is(AwaitingSync)) resetAndPropagateAssignmentError(group, Errors.REBALANCE_IN_PROGRESS) group.transitionTo(PreparingRebalance) info(&quot;Preparing to restabilize group %s with old generation %s&quot;.format(group.groupId, group.generationId)) val rebalanceTimeout = group.rebalanceTimeoutMs val delayedRebalance = new DelayedJoin(this, group, rebalanceTimeout) val groupKey = GroupKey(group.groupId) joinPurgatory.tryCompleteElseWatch(delayedRebalance, Seq(groupKey))&#125; DelayedOperation And DelayedOperationPurgatorypurgatory wiki DelayedJoin(简称DJ)是DelayedOperation(简称DO)的子类，DelayedOperationPurgatory(简称DOP)用于记录DO，并将超时的DO执行expired操作? DO用于执行延迟任务，参数只有一个超时时间，目前已有的实现类有： 比如DelayedFetch的操作允许Fetch等待一定数量的消息或者达到超时时间后再返回。 当DO完成给定的操作后，会调用onComplete方法(该方法需要子类实现)并且只会被调用一次, isComplete方法将返回true(通过原子变量AtomicBoolean实现)； forceComplete和tryComplete方法等能触发onComplete，其中前者已经在DO中实现了：def forceComplete(): Boolean = &#123; if (completed.compareAndSet(false, true)) &#123; // cancel the timeout timer cancel() onComplete() true &#125; else &#123; false &#125;&#125; 该方法将原子变量强行换成true(如果当前为false的话)，然后调用onComplete操作；后者需要子类实现：在判断是否达到complete条件后再调用forceComplete。 safeTryComplete是TryComplete的线程安全版： def safeTryComplete(): Boolean = &#123; synchronized &#123; tryComplete() &#125;&#125; 如果DO超时，将调用onExpiration操作(0.10.1.1版本中，DJ仍未实现该方法) WatchersDOP形象的定义了Watchers这个类用于存放和“观察”DO，使用到的数据结构是ConcurrentLinkedQueue。 watch：该方法将DO添加到队列中 tryComplteWatched：遍历队列，将已完成的DO从队列中移除，调用未完成DO的safeTryComplte方法，并记录在该方法中完成的DO数量。 purgeCompleted：该方法只是将已完成的移除掉，并返回移除的数量。 每个Watchers都与一些key关联(HashMap)，定义为watchersForKey Key的类型没有限制， 当key对应的DO全部完成后，key以及对应的Watchers一起从Map中移除。 其他参数及属性 timeoutTimer brokerId purgeInterval：清理基准线，当DOP中已完成的DO数量达到该基准线后开始清理操作 reaperenbaled：是否允许清除DO watchersForKey：存放watcher与对应的key expirationReaper：超时DO清道夫 tryCompleteElseWatch该方法将一个DO塞进Watchers中并与多个Key进行关联。如果每次与Key进行关联时都执行一次tryComplete操作成本很大。kafka选择了一个折中的策略，保证在该方法内最多调用两次tryComplete方法： 执行第一次tryComplete操作，成功就返回 遍历keys，如果DO未完成就将key与Watchers进行绑定，添加到watchersForKey 执行第二次tryComplete，成功就返回 依然未成功的话就添加到timeoutTimer中(进入这里面的DO将怎么处理？怎么才能再次触发onComplete操作呢？) 放到Timer中的DO在超时的时候会执行TimerTask#run()方法 DelayedOperation基础了TimerTask类，覆盖了父类的run方法： override def run(): Unit = &#123; if (forceComplete()) onExpiration()&#125; DelayedJoinGroupCoordinator中实现了DJ作为DO的各个方法，在分析这些方法前需要关注的是GroupMetadata 与 MemberMetadata的两个属性： notYetRejoinedMembers AND awaitingJoinCallback awaitingJoinCallback是Mebmer的属性，初始为null;当member所在的group处于PreparingReblance状态下，member向coordinator发送了JoinGroup请求，那么该字段用于存放将JoinGroupResult反馈的回调方法，在重平衡结束后或者coordinator执行出境操作等会将该字段重新置为Null notYetRejoinedMembers存放该group中没有awaitingJoinCallback的member，在Rebalance期间，该集合中存储的是那些没有发送JoinGroup请求的member。 tryComplete如果group中所有的成员都发送了JoinGroupRequest 就调用forceComplete方法(DO中的方法)：def tryCompleteJoin(group: GroupMetadata, forceComplete: () =&gt; Boolean) = &#123; group synchronized &#123; if (group.notYetRejoinedMembers.isEmpty) forceComplete() else false &#125;&#125; 留个问题 如果某个member迟迟不发送JoinGroup请求的话，那总不能永久等待吧？member在什么情况下会被移出group呢？(关键点在于DelayedHeartbeat的onExpireHeartbeat方法) onExpireHeartbeat如果coordinator听不到member的心跳：member.latestHeartbeat + member.sessionTimeoutMs &gt; heartbeatDeadline heartbeat的超时时间由consumer的session.timeout.ms控制【默认为100s】那么就会将member从group中移除：private def onMemberFailure(group: GroupMetadata, member: MemberMetadata) &#123; trace(\"Member %s in group %s has failed\".format(member.memberId, group.groupId)) group.remove(member.memberId) group.currentState match &#123; case Dead | Empty =&gt; case Stable | AwaitingSync =&gt; maybePrepareRebalance(group) case PreparingRebalance =&gt; joinPurgatory.checkAndComplete(GroupKey(group.groupId)) &#125;&#125; 如果当前group处于PreparingRebalance状态，那么将会将查下是否可以complete join操作。那么前面两个问题已经明朗了： 添加到DOP的timeoutTimer中的DO只是放入一个定时器内，超时后移除，DO能否在超时前执行onComplete操作完全靠外部触发； 如果某个group存在多个member，如果其中存在member非正常退出(即没有执行unsubscribe操作)，那么coordinator必须依赖心跳超时来检查该member是否dead，在此期间内的joinGroup请求无法立即得到响应。 onCompleteJoin疑惑 该方法的第一步看不懂：// remove any members who haven't joined the group yetgroup.notYetRejoinedMembers.foreach &#123; failedMember =&gt; group.remove(failedMember.memberId) // TODO: cut the socket connection to the client&#125; 能够执行onCompleteJoin说明notYetRejoinedMembers已经是空的了，这里的移除操作感觉多余了？？？？ JoinGroupResult：val joinResult = JoinGroupResult( members=if (member.memberId == group.leaderId) &#123; group.currentMemberMetadata &#125; else &#123; Map.empty &#125;, memberId=member.memberId, generationId=group.generationId, subProtocol=group.protocol, leaderId=group.leaderId, errorCode=Errors.NONE.code) group的leaderId采取先来后到的原则，新来的memberId作为leaderId。 对于非正常重启一个consumer所遇到的长时间等待可以用下图加深理解：","categories":[],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"test_blog","slug":"test-blog","date":"2018-04-04T03:22:14.000Z","updated":"2018-04-04T07:28:05.135Z","comments":true,"path":"2018/04/04/test-blog/","link":"","permalink":"http://yoursite.com/2018/04/04/test-blog/","excerpt":"","text":"this is titlethis is the second title//this is codepublic static void main(String[] args) &#123; System.out.println(\"hello world\");&#125;","categories":[],"tags":[{"name":"test","slug":"test","permalink":"http://yoursite.com/tags/test/"}]},{"title":"Hello World","slug":"hello-world","date":"2018-04-04T02:16:19.237Z","updated":"2018-04-04T02:16:19.239Z","comments":true,"path":"2018/04/04/hello-world/","link":"","permalink":"http://yoursite.com/2018/04/04/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new \"My New Post\" More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"Controller工作原理","slug":"Controller工作原理","date":"2017-04-28T02:55:56.000Z","updated":"2018-04-11T05:51:20.688Z","comments":true,"path":"2017/04/28/Controller工作原理/","link":"","permalink":"http://yoursite.com/2017/04/28/Controller工作原理/","excerpt":"","text":"[TOC] start up controller 引入Controller的目的是为了减小ZK的压力以及降低整个分布式系统的复杂度。 注册监听向zk注册监听两个实例： SessionExpirationListener：如果session时效了，zk会负责重连的，kafka这边不需要处理 LeaderChangeListener：监听集群的leader(即controller)发生改变，对于原leader需要执行resign的操作(onControllerResignation)将Leadership上交: de-register listeners：IsrChangeNotificationListener、ReassignedPartitionsListener、PreferredReplicaElectionListener、ReassignedPartitionsIsrChangeListeners 关闭的功能有：删除topic、自动重平衡管理、replica与partition的状态机等 start Elector 首先要判断下zookeeper下面是否存在永久节点：/controller，该节点存储着controller的信息，如：{&quot;version&quot;:1,&quot;brokerid&quot;:2,&quot;timestamp&quot;:&quot;1493345638688&quot;} 抢注leader 从/controller目录下获取controllerId，成功获取到就返回amILeader。这样就能确保如果有broker注册controller(向zk的/controller目录下面创建临时节点)成功，其他broker就不再尝试注册 抢注leader：使用ZKCheckedEphemeral注册临时节点，下面是controller(broker)关闭的情况下，broker2注册controller成功的输出日志：[2017-04-28 10:13:58,689] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)[2017-04-28 10:13:58,692] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)[2017-04-28 10:13:58,693] INFO 2 successfully elected as leader (kafka.server.ZookeeperLeaderElector)[2017-04-28 10:13:59,592] INFO New leader is 2 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener) onControllerFailover在抢注成功后，该broker需要担负起Leader的职责，包括以下几个方面： 1. 改朝换代读取 /controller_epoch 的值，获取当前controller的纪元(朝代)，然后增加1 2. 注册ZK监听程序对ZK上的节点进行监听： /admin/reassign_partitions：监听partition重分配的动作 isr_change_notification：该节点用于通知parition的ISR变化 /admin/preferred_replica_election: 以上都是通过controller注册的，下面是通过特定的状态机向ZK注册监听的： PartitionStateMachine：描述parition的状态机 /brokers/topics：TopicChangeListener /admin/delete_topics：DeleteTopicsListener replicaStateMachine：描述replicas的状态机 /brokers/ids：BrokerChangeListener 最后，对每个topic添加PartitionModificationsListener,zk路径为：/brokers/topics/topic_name 3. 初始化controller上下文收集：brokers、topics、partitions-leader、ISR等信息；开启ControllerChannelManager和partitionStateMachine 4. 进行分区重分配和分区leader选举操作详见 partition reassign PreferredReplicaElection 5. 发送metadata数据发送数据到集群上所有的broker，包括live和shutdown的 6. 开启分区重平衡线程分区的重平衡是否开启由参数auto.leader.rebalance.enable控制，默认开启；线程的执行间隔由leader.imbalance.check.interval.seconds控制，默认为300 所有触发Elect的情况partition reassign在Kafka-manager上对topic——testReassign(包含3个分区)进行手动partition分配： 这是重分配之前的分区情况： 调整0和1的分区Replicas： 执行Reassign Partitions，观察日志： PartitionsReassignedListener感知到了ZK上/admin/reassign_partitions节点上内容发生了变化[PartitionsReassignedListener on 2]: Partitions reassigned listener fired for path /admin/reassign_partitions. Record partitions to be reassigned &#123;&quot;version&quot;:1,&quot;partitions&quot;:[&#123;&quot;topic&quot;:&quot;testReassign&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[1,2]&#125;,&#123;&quot;topic&quot;:&quot;testReassign&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[2,3]&#125;,&#123;&quot;topic&quot;:&quot;testReassign&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[3,1]&#125;]&#125; 由于分区2未进行重分配，其原来的replicas与现在的一致，因此无视该Reassign请求：kafka.common.KafkaException: Partition [testReassign,2] to be reassigned is already assigned to replicas 1,2. Ignoring request for partition reassignment 接下来对分区0和1进行重分配，就拿1来说：[Controller 2]: Handling reassignment of partition [testReassign,1] to new replicas 2,3 [Controller 2]: New replicas 2,3 for partition [testReassign,1] being reassigned not yet caught up with the leader [Controller 2]: Updated path /brokers/topics/testReassign with &#123;&quot;version&quot;:1,&quot;partitions&quot;:&#123;&quot;2&quot;:[1,2],&quot;0&quot;:[2,3],&quot;1&quot;:[2,3,1]&#125;&#125; for replica assignment [Controller 2]: Updated assigned replicas for partition [testReassign,1] being reassigned to 2,3,1 [[Controller 2]: Updating leader epoch for partition [testReassign,1]. [Controller 2]: Updated leader epoch for partition [testReassign,1] to 1 [Replica state machine on controller 2]: Invoking state change to NewReplica for replicas [Topic=testReassign,Partition=1,Replica=2] [Controller 2]: Waiting for new replicas 2,3 for partition [testReassign,1] being reassigned to catch up with the leader 疑问：往/brokers/topics/testReassign中写入的为啥是[2,3,1]而不是[2,3]呢？留个坑：在KafkaController.onPartitionReassignment方法中找答案吧~该方法在多处被调用 partition state machine下图简单描述了partition的4种状态： 状态机通过一个map类型的partitionState来存放所有分区的当前状态。 start up此时cluster的controller已经产生，controller通过读取ZK的partition和ISR节点信息判断每个partition的当前状态。 具体是判断每个分区对应的LeaderIsrAndControllerEpoch信息与当前的Epoch是否吻合： 如果吻合，则是OnLine状态 存在但不吻合，则是OffLine状态 不存在信息，则是New状态 划分好了当前的状态后，下面要将new和offline的转化成Online 如何转化呢？当然是选举leader咯，关键代码在OfflinePartitionLeaderSelector这个类里，下面这个表是选举时遇到的几种情况ISR|replicas|result—|—|—(1,2)|(1,2)|leader = 1null|(2,3)|unclean enabled ? leader=2 : NoReplicaOnlineExceptionnull|null|NoReplicaOnlineException 如当前有个repilca设置为1的topic：”jjhtest”，当前leader与isr的分配为： 接下来我重启broker3，会发生什么呢？ 由于每个分区的replicas都是固定的(不考虑手动分配)，关闭broker3将导致分区1,4,7的replicas中无可用的broker，这3个分区将无法分配到broker，进入offline状态 如果分区的replica&gt;1，在shutDownBroker方法中：broker作为leader的分区状态转移是online ==&gt; online，leader选举的selector为：ControlledShutdownPartitionLeaderSelector broker3恢复后，以上3个分区由offline状态向online转变，触发leader的选举 选举的过程： partitionReplicaAssignment该变量是个Mutable Map，存放的是每个分区对应的replicas信息。这个信息有两个来源： TopicChangeListener监听ZK上的topic变化，比如新增了topic，那么就会从ZK获取分区的replicas分配信息 PartitionModificationsListener监听parition的变化，比如新增了分区，会从ZK获取新增分区的replicas信息。 electLeaderForPartition当partition的状态由offline或者online ==&gt; online时，会通过不同的PartitionLeaderSelector选举leader(LeaderSelector缩写为LS)： 每次成功执行了leader select，都会更新leader cache(controllerContext.partitionLeadershipInfo) preferred replica election 在controller启动的过程中会执行一次preferredReplicaElection(简称PRE)，并创建一个间隔为leader.imbalance.check.interval.seconds(default:300)的定时任务执行PartitionRebalance操作，该操作会触发PRE kafka平衡策略的实现依赖于以下几方面的因素： 在不考虑手动分配分区的情况下，每个分区分配的Replicas是写死的，包括顺序都是固定的。 在出现broker挂掉的情况下，leader的重新选举能保证消息不丢失(未触发脏选举)，而PRE(首选备份选举)能保证broker恢复后分区的leader能均衡分布在集群上。 小实验有一个分区数为6，备份数为2的topic：”TheOne”，当前的分配状态为： 关闭broker3后分区4和5的leader重新选举： broker3恢复后，又重新加入到了各个topic的ISR中(IsrChangeNotificationListener被触发)： 一段时间后，触发PRE： [Controller 1]: Starting preferred replica leader election for partitions [TheOne,5] (kafka.controller.KafkaController)[Partition state machine on Controller 1]: Invoking state change to OnlinePartition for partitions [TheOne,5] (kafka.controller.PartitionStateMachine)[PreferredReplicaPartitionLeaderSelector]: Current leader 1 for partition [TheOne,5] is not the preferred replica. Trigerring preferred replica leader election (kafka.controller.PreferredReplicaPartitionLeaderSelector)[Controller 1]: Partition [TheOne,5] completed preferred replica leader election. New leader is 3 (kafka.controller.KafkaController) leader &amp; ISR又恢复了初始状态，达到了均衡。 PRE的选举操作由preferredReplicaPartitionLeaderSelector完成，状态为online ==&gt; online 思考：动态扩展broker如何实现？动态扩展broker能否实现分区的均衡扩展呢？ partition reblance 分区重平衡的间隔上面提到过了，默认为5分钟。 触发重平衡由失衡率(imbalanceRatio)决定:$$ ratio = Sum(partitonsNotLeaded)/Sum(partitonsShouldLeaded)$$当ratio大于leader.imbalance.per.broker.percentage(默认10%)时会触发重平衡 DEBUG: topics not in preferred replica Map() (kafka.controller.KafkaController)TRACE: leader imbalance ratio for broker 2 is 0.000000 (kafka.controller.KafkaController)DEBUG: topics not in preferred replica Map() (kafka.controller.KafkaController)TRACE: leader imbalance ratio for broker 1 is 0.000000 (kafka.controller.KafkaController)DEBUG: topics not in preferred replica Map([TheOne,4] -&gt; List(3, 2), [TheOne,5] -&gt; List(3, 1),...) (kafka.controller.KafkaController)TRACE: leader imbalance ratio for broker 3 is 0.951613 (kafka.controller.KafkaController) 重平衡的过程主要是执行PRE Replica state machine与partition相比多了3种状态 create topic新建topic涉及到partition以及replica状态的改变： NoExistent ==&gt; NewInvoking state change to NewPartition for partitions [TT,6],...(kafka.controller.PartitionStateMachine)Invoking state change to NewReplica for replicas [Topic=TT,Partition=6,Replica=2],[Topic=TT,Partition=6,Replica=3],... (kafka.controller.ReplicaStateMachine) 在新建topic后，ZK就会为该topic分配replicas New ==&gt; Online#partition state machineInvoking state change to OnlinePartition for partitions [TT,6],...Live assigned replicas for partition [TT,6] are: [List(2, 3)]Initializing leader and isr for partition [TT,6] to (Leader:2,ISR:2,3,LeaderEpoch:0,ControllerEpoch:30)#replica state machineInvoking state change to OnlineReplica for replicas [Topic=TT,Partition=6,Replica=2],[Topic=TT,Partition=6,Replica=3],... ReplicaDeletionStarted该状态一般在进行手动分区分配时产生的，以parition reassign实验试验中的分区1为例：replicas：[3,1] ==&gt; [2,3] broker2成为NewReplica：Invoking state change to NewReplica for replicas [Topic=testReassign,Partition=1,Replica=2] broker2进入OnlineReplica：Invoking state change to OnlineReplica for replicas [Topic=testReassign,Partition=1,Replica=2] broker1成为OfflineReplica，从ISR中移除： Invoking state change to OfflineReplica for replicas [Topic=testReassign,Partition=1,Replica=1]Removing replica 1 from ISR 3,1 for partition [testReassign,1] broker1进入ReplicaDeletionStarted状态:Invoking state change to ReplicaDeletionStarted for replicas [Topic=testReassign,Partition=1,Replica=1] broker1进入ReplicaDeletionSuccessful ：nvoking state change to ReplicaDeletionSuccessful for replicas [Topic=testReassign,Partition=1,Replica=1] broker1进入NonExistentReplica：Invoking state change to NonExistentReplica for replicas [Topic=testReassign,Partition=1,Replica=1] ZKListener 详解 下面对Controller中使用到的一些监听ZK节点及子节点变化的listener进行梳理 listener 监听的节点 用处 处理逻辑 BrokerChangeListener /brokers/ids 子节点 在ReplicaStateMachine中使用 BCL ISRChangeNotificationListener /isr_change_notification 子节点 Controller用于监听各个partition的ISR变化 ICNL PartitionModificationsListener /brokers/topics/topic_name 监听对应topic分区的变化(只允许增加) PML LeaderChangeListener /controller 监听集群leader的变化 注册监听 Broker Change Listener/brokers/ids目录下有多个以broker_id命名的子节点，每个子节点上存储着与broker相关的信息，如：&#123;&quot;jmx_port&quot;:9999,&quot;timestamp&quot;:&quot;1493886226618&quot;,&quot;endpoints&quot;:[&quot;PLAINTEXT://ip:9092&quot;],&quot;host&quot;:&quot;ip&quot;,&quot;version&quot;:3,&quot;port&quot;:9092&#125; 当这些子节点的内容发生变化时，controller感知到后会统计出变化的情况： broker2 shutdown：Newly added brokers: , deleted brokers: 2, all live brokers: 1,3 broker2 startup： Newly added brokers: 2, deleted brokers: , all live brokers: 1,2,3 delete brokershutdownBroker 该方法与KafkaServer中的shutdown方法的区别在于前者用于处理ControlledShutdown请求，将分区的职责转移出去，而后者是关闭brokerServer的一堆服务。 需要处理的分区为：$ List(partition) = { partition | id ∈ Replicas(partition) &amp;&amp; replicaFactor(partition) &gt; 1 } $ 对于作为leader的分区，执行leader的重选举(ControlledShutdownLS) 对于作为普通replica的分区： 关闭ReplicaRequest,如broker3是TheOne-1的replica，在关闭broker3时controller会向3发送关闭replica请求的请求：The stop replica request (delete = false) sent to broker 3 is [Topic=TheOne,Partition=1,Replica=3](kafka.controller.ControllerBrokerRequestBatch) broker3收到StopReplica请求后调用ReplicaManager的stopReplicas移除了相关的replica的Fetcher：[ReplicaFetcherManager on broker 3] Removed fetcher for partitions TheOne-1 将broker3的Replica状态置为OfflineReplica onBrokerFailure步骤如下： 在shutdownBroker的处理的分区中有一项要求是：replicaFactor &gt; 1，而对于replicaFactor = 1的分区来说，如果其leader所在的broker关闭了，那么该分区的状态将置为OfflinePartition。筛选的依据是其leader是否为关闭的broker(其他类型的分区在上面的流程中要么leader重新选举过了，要么只是改变ISR) 尝试使用OfflinePartitionLS将offline和new类型的partition转化为Online 集体性的将该broker的replica的状态置为OfflineReplica 感觉重复操作了，因为shutdownBroker阶段也有这操作。不同点在于shutdownBroker只处理replica&gt;1分区的replica状态。 如果第一步操作未执行，那么将向其他broker发送一个UpdateMetadataRequest onBrokerStartup主要处理的依然是分区、replica、ISR以及leader的转化： 发送UpdateMetadataRequest（具体原因不明） 将该broker的replica状态置为OnlineReplica 尝试使用OfflinePartitionLS将offline和new类型的partition转化为Online，这一步的主要目的是为了将onBrokerFailue阶段呗置为OffLinePartition的分区恢复成Online：[OfflinePartitionLeaderSelector]: No broker in ISR is alive for [jjhtest,1]. Pick the leader from the alive assigned replicas: 3 [OfflinePartitionLeaderSelector]: No broker in ISR is alive for [jjhtest,1]. Elect leader 3 from live brokers 3. There is potential data loss. [OfflinePartitionLeaderSelector]: Selected new leader and ISR {&quot;leader&quot;:3,&quot;leader_epoch&quot;:23,&quot;isr&quot;:[3]} for offline partition [jjhtest,1] 判断是否需要执行分区重分配的操作 ISR Change Notification Listener集群正常运行时/isr_change_notification节点下面是没有子节点的，当ISR发生变化的时候，如重启某个broker，那些ISR原来包含该broker的分区需要调整ISR，因此会创建这些partition的子节点。 下面是broker3挂掉后，TheOne这个topic的ISR： 在broker3恢复后，ISNL感知到了某些partition的ISR发生了变化，进行下面3步操作： 根据子节点的内容更新对应parition的leader以及ISR cache (从ZK上获取) 向集群所有节点发送MetadataRequest：DEBUG Sending MetadataRequest to Brokers:ArrayBuffer(1, 2, 3) for TopicAndPartitions:Set([TheOne, 2], [TheOne, 4],...) 删除子节点 Partition Modifications Listener Contorller为每个topic都设置了一个PartitionModificationsListener，用于监听新增分区的操作 下面是将TheOne的分区数增加3，PML所感知到的信息：[AddPartitionsListener on 1]: Partition modification trigered &#123;&quot;version&quot;:1,&quot;partitions&quot;:&#123;&quot;8&quot;:[3,2],&quot;4&quot;:[3,2],&quot;5&quot;:[3,1],&quot;6&quot;:[1,3],&quot;1&quot;:[1,3],&quot;0&quot;:[1,2],&quot;2&quot;:[2,3],&quot;7&quot;:[2,1],&quot;3&quot;:[2,1]&#125;&#125; for path /brokers/topics/TheOne[AddPartitionsListener on 1]: New partitions to be added Map([TheOne,7] -&gt; List(2, 1), [TheOne,6] -&gt; List(1, 3), [TheOne,8] -&gt; List(3, 2)) 新增了Partition，ZK已经为这些partition分配了replicas，在ZK上每个topic的分区上存储着的信息如：{&quot;controller_epoch&quot;:30,&quot;leader&quot;:3,&quot;version&quot;:1,&quot;leader_epoch&quot;:0,&quot;isr&quot;:[3,2]} 拿到这些消息后，Controller要做的第一件事就是将新增的分区的replicas信息添加到partitionReplicaAssignment中，接下来才是处理这些新建的分区的状态、leader等，这个操作与create topic的处理如出一辙，区别在于前者是对新增的分区进行处理，后者是对这个topic的所有分区进行处理","categories":[],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"ISR消息管理","slug":"ISR消息管理","date":"2017-04-24T09:09:57.000Z","updated":"2018-04-11T05:50:57.882Z","comments":true,"path":"2017/04/24/ISR消息管理/","link":"","permalink":"http://yoursite.com/2017/04/24/ISR消息管理/","excerpt":"","text":"[TOC] 疑问 leader是在何时更新Highwater的？ kafka-manager上出现Lag为负值是什么原因造成的？ Log中的消息被删除时，ISR之间是如何协调的？ 下面所有的讨论都是基于一个包含3个broker的kafka集群而言的 Replicaleader vs followers如果将所有的topic的replicas设置为2(_consumer_offsets除外)，那么对于每个partition而言其Log存在于两个broker上，其中一个作为leader，另一个作为followers 下图是一个包含3个分区的topic的replicas以及leader分布情况： leader与followers的职责之前在kafka-consumer剖析的文章中介绍过high watermark(简称HW)以及log end offset(简称LEO)的概念。作为leader，其主要职责是： 将消息及offset写入Local log &amp; offset 在followers完全备份了消息后(leader应该是会收到通知)，更新HW leader并不需要维护LEO的值，因为在Log中有一个nextOffsetMetadata属性就是每个Log维护的最新offset的信息 反观followers，其职责则体现在与leader的交互上： 备份消息，然后通知leader 更新LEO的值 创建Replica因为每个partition都有对应的replicas，所以创建replica的操作是在Partition中执行的，具体的方法是getOrCreateReplica：if (isReplicaLocal(replicaId)) &#123; //创建Log文件 val config = LogConfig.fromProps(...) val log = logManager.createLog(TopicAndPartition(topic, partitionId), config) //获取checkPoint文件 val checkpoint = replicaManager.highWatermarkCheckpoints(log.dir.getParentFile.getAbsolutePath) val offsetMap = checkpoint.read val offset = offsetMap.getOrElse(TopicAndPartition(topic, partitionId), 0L).min(log.logEndOffset) val localReplica = new Replica(replicaId, this, time, offset, Some(log)) addReplicaIfNotExists(localReplica)&#125; else &#123; val remoteReplica = new Replica(replicaId, this, time) addReplicaIfNotExists(remoteReplica)&#125;getReplica(replicaId).get 其中： getReplica与addReplicaIfNotExists都对assignedReplicaMap进行操作 checkpoint里维护着该log.dir下面所有topic-parition与offset的对应关系 log.dir是Log文件所在目录，log.dir.getParentFile就是server.properties中定义的log.dirs ReplicaManager 创建Replica的调用路径是ReplicaManager.becomeLeaderOrFollower-&gt;makeFollowers。ReplicaManager是broker范畴的，管理着broker上面所有的partition OffsetCheckPoint在多磁盘的环境中，log.dirs会定义在多个磁盘上，这样就能将Partiton分布在不同的磁盘上。 每个磁盘中的Log目录下都维护着3个OffsetCheckPoint文件：: recovery-point-offset-checkpoint: replication-offset-checkpoint：维护parition与offset信息: cleaner-offset-checkpoint replication-offset-checkpoint的内容如下：021__consumer_offsets 16 0__consumer_offsets 49 124admin.benchmark 9 24564634test 13 16709theOne 18 0__consumer_offsets 4 6... 其中： 第一行是CurrentVersion的值，默认是0 第二行是当前Log目录下面分区的数量 后面紧跟着的21行是分区以及对应的offset信息，格式为：$topic $partition $offset 在ReplicaManager中会将所有log目录下面的replication-offset-checkpoint组成一个名为highWatermarkCheckpoints的Map:val highWatermarkCheckpoints = config.logDirs.map(dir =&gt; (new File(dir).getAbsolutePath, new OffsetCheckpoint(new File(dir,ReplicaManager.HighWatermarkFilename)))).toMap 其更新操作是由一个定时任务控制的，每隔replica.high.watermark.checkpoint.interval.ms(默认5s)的时间会将所有log目录下的raplica的HW值写入到对应的replication-offset-checkpoint文件中。该定时任务是在becomeLeaderOrFollower方法中被开启的。 appendMessages在Log分析曾提到过appendMessages方法，该方法内先将消息写入local(即Leader的Log)，然后判断ack是否=-1来决定是否需要创建延迟的producer请求(不立即反馈，需要等待备份完成，由delayedProducePurgatory进行管理)。该请求是从leader发往followers的，内容包含： delayedMs：即producer配置的request.timeout requiredOffset: Leader在写入消息后的InextOffsetMetadata值(用LogAppendInfo.lastOffset + 1表示) 在ack = -1的策略下，leader必须在所有的followers都将消息备份的情况下，才会向producer发送反馈，而判断消息是否已完整备份的方法是Partition.checkEnoughReplicasReachOffset：def checkEnoughReplicasReachOffset(requiredOffset: Long): (Boolean, Errors) = &#123; leaderReplicaIfLocal() match &#123; case Some(leaderReplica) =&gt; val curInSyncReplicas = inSyncReplicas //对ISR中所有replicas的LEO校验是否已跟上leader的步伐(包括leader) def numAcks = curInSyncReplicas.count &#123; r =&gt; if (!r.isLocal) if (r.logEndOffset.messageOffset &gt;= requiredOffset) &#123; true &#125; else false else true &#125; val minIsr = leaderReplica.log.get.config.minInSyncReplicas if (leaderReplica.highWatermark.messageOffset &gt;= requiredOffset) &#123; if (minIsr &lt;= curInSyncReplicas.size) (true, Errors.NONE) else (true, Errors.NOT_ENOUGH_REPLICAS_AFTER_APPEND) &#125; else (false, Errors.NONE) case None =&gt; (false, Errors.NOT_LEADER_FOR_PARTITION) &#125;&#125; 第一个返回参数表示是否有足够多的replicas达到了requiredOffset 如果HW &lt; requiredOffset，表明leader还未收到足够多的replicas的response HW &gt;= requiredOffset表明HW已经更新过了，此时如果ISR的数量小于misISR，那么就报NOT_ENOUGH_REPLICAS_AFTER_APPEND错 如果当前ReplicaManger发现local不再是leader了，说明这个broker出现问题了，报NOT_LEADER_FOR_PARTITION错 Increment HWHW是由leader维护的，其更新时机主要有两种： ISR发生变化，包括： 新的broker成为leader shrink ISR expand ISR Replicas已备份完新的消息，判别的方法有两种： ISR中Replicas中的最小LEO值大于HW HW的LogOffsetMetadata存在一个老的log segment中，表明上一次Producer请求已处理完成(即消息已经在完成备份) ShrinkIsrbecomeLeaderOrFollowerReplcaFetcher启动过程ReplicaManger相关日志记录以broker3启动日志为例：在Log加载、处理完后，首先是unblock操作：[2017-04-25 13:35:57,270] DEBUG [Replica Manager on Broker 3]: Request key __consumer_offsets-25 unblocked 0 producer requests. (kafka.server.ReplicaManager)[2017-04-25 13:35:57,270] DEBUG [Replica Manager on Broker 3]: Request key __consumer_offsets-25 unblocked 0 producer requests. (kafka.server.ReplicaManager)[2017-04-25 13:35:57,270] DEBUG [Replica Manager on Broker 3]: Request key __consumer_offsets-25 unblocked 0 fetch requests. (kafka.server.ReplicaManager)[2017-04-25 13:35:57,270] DEBUG [Replica Manager on Broker 3]: Request key __consumer_offsets-25 unblocked 0 fetch requests. (kafka.server.ReplicaManager) 应该是解封在关闭阶段被阻塞的一些request 下面开启ReplicaFetcherThread：[2017-04-25 13:35:57,367] INFO [ReplicaFetcherThread-0-1], Starting (kafka.server.ReplicaFetcherThread)[2017-04-25 13:35:57,384] INFO [ReplicaFetcherThread-3-1], Starting (kafka.server.ReplicaFetcherThread)[2017-04-25 13:35:57,384] INFO [ReplicaFetcherThread-1-2], Starting (kafka.server.ReplicaFetcherThread)[2017-04-25 13:35:57,398] INFO [ReplicaFetcherThread-2-2], Starting (kafka.server.ReplicaFetcherThread)[2017-04-25 13:35:57,406] INFO [ReplicaFetcherThread-1-1], Starting (kafka.server.ReplicaFetcherThread)[2017-04-25 13:35:57,414] INFO [ReplicaFetcherThread-0-2], Starting (kafka.server.ReplicaFetcherThread)[2017-04-25 13:35:57,423] INFO [ReplicaFetcherThread-2-1], Starting (kafka.server.ReplicaFetcherThread)[2017-04-25 13:35:57,435] INFO [ReplicaFetcherThread-3-2], Starting (kafka.server.ReplicaFetcherThread) 数字编号的含义是什么呢？？ 接下来是添加Fetcher请求，向Remote Broker请求那些本地不是leader的分区的数据。摘取片段如下：INFO [ReplicaFetcherManager on broker 3] Added fetcher for partitions List([topic1-8, initOffset 6538 to broker BrokerEndPoint(1,10.45.4.9,9092)] ,[topic2-9, initOffset 0 to broker BrokerEndPoint(1,10.45.4.9,9092)]...) ReplicaFetcherThread 每个ReplicaManager不仅要维护一个producer的炼狱(delayedProducePurgatory)，还维护了一个fetcher的炼狱(delayedFetchPurgatory)。fetch这个操作不仅仅是由consumer触发的，followers备份消息也是通过向leader fetch实现的。 ReplicaFetcherManager ReplicaFetcherManager管理着ReplicaFetcherThread的创建和关闭工作。 该manager的命名格式为：“ReplicaFetcherManager on broker $ID” thread fetcher的数量由num.replica.fetchers控制：(31 * topic.hashCode() + partitionId) % numFetchers，当该参数设置为4，那么 $fetcherId∈[0,1,2,3]$，对于3节点replicas=2的集群，每个broker需要$4*2=8$个fetcherThread：val partitionsPerFetcher = partitionAndOffsets.groupBy&#123; case(topicAndPartition, brokerAndInitialOffset) =&gt; BrokerAndFetcherId(brokerAndInitialOffset.broker, getFetcherId(topicAndPartition.topic, topicAndPartition.partition))&#125; 上面的代码中将partition-broker这个map按照broker-&gt;fetcherId的对应关系进行分组。 fetcherThread的命名方式为：ReplicaFetcherThread-fetcherId-brokerId ReplicaFetcherThread是个定时执行的线程，执行间隔由replica.fetch.backoff.ms控制，默认为1s 每个ReplicaFethcerThread的fetch目标是一个broker上的若干topic-partition 工作流程 processPartitionData当前：: broker2作为test-1的follower: 其LEO值为17314: leader的HW=17314: FetchRequest中的fetchOffset = 17314 收到一条消息： [ReplicaFetcherThread-3-1], Follower 2 has replica log end offset 17314 for partition test-1. Received 45 messages and leader hw 17314 对log执行append操作 [ReplicaFetcherThread-3-1], Follower 2 has replica log end offset 17315 after appending 45 bytes of messages for partition test-1 与appendMessagesToLeader时不相同的是，follower执行append操作不会再进行offset配置操作，用得就是leader传过来的offset 设置follower的HW值[ReplicaFetcherThread-3-1], Follower 2 set replica high watermark for partition [test,1] to 17314 1s后再次fetch到消息：[ReplicaFetcherThread-3-1], Follower 2 has replica log end offset 17315 for partition test-1. Received 45 messages and leader hw 17315[ReplicaFetcherThread-3-1], Follower 2 has replica log end offset 17316 after appending 45 bytes of messages for partition test-1[ReplicaFetcherThread-3-1], Follower 2 set replica high watermark for partition [test,1] to 17315 由上面的日志可以注意到： LEO的值由17314 =&gt; 17315，这是因为前面执行的Log.append操作使得nextOffsetMetadata的值+1 leader的HW值变成了17315,这是由于leader检测到了followers(就是broker2)LEO的最小值已经变成了17315，所以更新了HW值,具体实现在Increment HW中有介绍 handleOffsetOutOfRange 当ReplicaFether的fetchOffset不在leader的offset之内(即大于最大值或者小于最小值)，那么就会收到OffsetOutOfRangeException 假设当前test-1这个partition的leader为1，新增broker2作为follower broker2在catch up的过程中broker1挂了，broker2被选为leader。(需要unclean.leader.election.enable配置为1，才能允许这样的脏选举) 情况一、Replica fetchOffset &gt; leader LEObroker1在恢复后，成为了follower，向leader发送ReplicaFetcherRequest，其中fetchOffset=7，该值大于leader的LEO，所以需要将broker1上该分区的Log执行truncate操作使得LEO值与leader保持一致。 值得注意的是，这样的truncate操作后，follower与leader的消息并不完全一致的，上例中，offset为3和4的消息就是不一致的 情况二、Replica fetchOffset &lt; leader start offset broker1在恢复之前，broker2添加了很多消息，并且也删除了一个消息，导致其最小的offset大于broker1中的LEO，这种情况下，broker1中的所有消息都没有意义了(因为ISR中的leader不再维护这些消息)，所以就删除掉所有的segment，然后fetch leader的第一条消息 Kafka_0.10.1.1版本对于收到OffsetOutOfRangeException时follower的LEO处于leader开始与LEO之间的情况没有对策。","categories":[],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"SocketServer工作原理","slug":"SocketServer工作原理","date":"2017-04-01T08:33:36.000Z","updated":"2018-04-11T05:53:01.744Z","comments":true,"path":"2017/04/01/SocketServer工作原理/","link":"","permalink":"http://yoursite.com/2017/04/01/SocketServer工作原理/","excerpt":"","text":"kafka的socket server是基于java NIO,使用Reactor模式开发的。socketserver主要用于处理kafka server对外提交网络请求的操作,用于检查连接数,把请求添加到请求的队列中,对KafkaApis提供操作支持. 其线程模型为： 一个Acceptor线程接受/处理所有的新连接 N个Processor线程,每个Processor都有自己的selector,从每个连接中读取请求。数量由num.network.threads控制，默认为3 M个Handler线程处理请求,并将产生的请求返回给Processor线程用于写回客户端。数量由queued.max.requests控制，默认为500 Acceptor每个broker只有一个acceptor进程每个endPoint(由server.properties中的listeners定义)对应一个Acceptor，采用轮询的方式来处理新的连接，步骤如下： 1. 新建ServerSocketChannel使用endPoint的ip:portstrong text作为channel监听的socket地址：val serverChannel = ServerSocketChannel.open()serverChannel.configureBlocking(false)if (recvBufferSize != Selectable.USE_DEFAULT_BUFFER_SIZE) serverChannel.socket().setReceiveBufferSize(recvBufferSize)serverChannel.socket.bind(socketAddress) recvBufferSize的大小由socket.receive.buffer.bytes控制，默认是100KB，目前生产环境上配置的是1MB 2. selector绑定channel，开始工作 首先注册一个OP_ACCEPT事件serverChannel.register(selector, SelectionKey.OP_ACCEPT) 等待客户端的连接val ready = nioSelector.select(500) 采用Round Robin的方式将连接分配给processor进行处理 if(ready &gt; 0) &#123; val keys = selector.selectedKeys() val iter = keys.iterator() while(iter.hasNext &amp;&amp; isRunning) &#123; var key: SelectionKey = null key = iter.next iter.remove() if(key.isAcceptable) accept(key, processors(currentProcessor)) // round robin to the next processor thread currentProcessor = (currentProcessor + 1) % processors.length &#125; &#125; 接受客户端的连接，并将获得的SocketChannel交给processor def accept(key: SelectionKey, processor: Processor) &#123; //根据SelectionKey获取对应的serverSocketChannel val serverSocketChannel = key.channel().asInstanceOf[ServerSocketChannel] //调用accept方法建立与客户端的连接 val socketChannel = serverSocketChannel.accept() socketChannel.configureBlocking(false) socketChannel.socket().setTcpNoDelay(true) socketChannel.socket().setSendBufferSize(sendBufferSize) processor.accept(socketChannel)&#125; sendBufferSize由socket.send.buffer.bytes控制 至此，Acceptor的工作就完成了，接下来处理下一个连接请求。 ProcessorProcessor有两个重要的概念： newConnections：Processor在新收到一个从Acceptor转发过来的SocketChannel时先存放到该链表中，在运行时从链表中拿出一个Channel与客户端的ID(这个ID由本地ip:port+远程ip:port构造)进行绑定，并注册OP_READ inflightResponses：用于存放正在发送或者等待发送的服务器响应报文，如果成功发送了就移除掉 processor的运行模式跟客户端的NetworkClient相似while(isRunning)&#123; configureNewConnections() processNewResponses() poll() processCompletedReceives() processCompletedSends() processDisconnected()&#125; 其中Selector的poll方法是跟客户端共用的。 processCompletedReceivesprivate def processCompletedReceives() &#123; selector.completedReceives.asScala.foreach &#123; receive =&gt; val openChannel = selector.channel(receive.source) val session = &#123; val channel = if (openChannel != null) openChannel else selector.closingChannel(receive.source) RequestChannel.Session(new KafkaPrincipal(KafkaPrincipal.USER_TYPE, channel.principal.getName), channel.socketAddress) &#125; val req = RequestChannel.Request(processor = id, connectionId = receive.source, session = session, buffer = receive.payload, startTimeMs = time.milliseconds, listenerName = listenerName, securityProtocol = securityProtocol) requestChannel.sendRequest(req) selector.mute(receive.source) &#125;&#125; completedReceives中存放的是客户端的请求(NetworkReceive) receive.source指的是客户端ID selector的mute操作会将取消对应channel的OP_READ注册，这一点与客户端不同，client在与server建立连接后，channel上的OP_READ状态会一直保持着，因为client无法预知server的数据会在什么时候到来。而server则是在建立连接后，注册OP_READ，在收到client的请求后取消读。 server根据收到的请求，组建了一个响应的包,然后放到了requestChannel中。 processCompletedSendsprivate def processCompletedSends() &#123; selector.completedSends.asScala.foreach &#123; send =&gt; val resp = inflightResponses.remove(send.destination).getOrElse &#123; throw new IllegalStateException(s&quot;Send for $&#123;send.destination&#125; completed, but not in `inflightResponses`&quot;) &#125; resp.request.updateRequestMetrics() selector.unmute(send.destination) &#125;&#125; completedSends存放的是已经成功发送的响应，因此需要将其从inflightResponses中移除 selector.unmute方法能将channel注册OP_READ 那么问题来了：放到requestChannel中的request和response是如何被处理的呢？ 我们先来看下requestChannel：每个服务端只存在一个RequestChannel，用于连接Processor与Handler，他定义了两个阻塞队列： requestQueue：缓存服务端发送的request，大小为queued.max.requests responseQueues：每个processor都有一个队列 KafkaRequestHandlerSocketServer在初始化阶段会创建一个Handler的线程池：requestHandlerPool = new KafkaRequestHandlerPool(config.brokerId, socketServer.requestChannel, apis, time, config.numIoThreads) KafkaRequestHandler的数量由num.io.threads控制，默认为8。val runnables = new Array[KafkaRequestHandler](numThreads)for(i &lt;- 0 until numThreads) &#123; runnables(i) = new KafkaRequestHandler(i, brokerId, aggregateIdleMeter, numThreads, requestChannel, apis, time)&#125; 他的run方法也非常简单，就是从RequestChannel中获取request，然后调用KafkaApis对请求进行处理：req = requestChannel.receiveRequest(300)apis.handle(req) KafkaApis在处理完成后，会调用sendResponse方法。 ChannelBuildersSocketServer中的selector初始化过程：private val selector = new KSelector( maxRequestSize, connectionsMaxIdleMs, metrics, time, &quot;socket-server&quot;, metricTags, false, ChannelBuilders.create(protocol, Mode.SERVER, LoginType.SERVER, channelConfigs, null, true)) 其中ChannelBuilders是根据安全策略来创建KafkaChannel的 create channel using protocole首先来看下第一个参数：protocol，该参数是由socketServer初始化时创建Processor的时候根据EndPoint中声明的protocolType决定的：endpoints.values.foreach &#123; endpoint =&gt; val protocol = endpoint.protocolType val processorEndIndex = processorBeginIndex + numProcessorThreads for (i &lt;- processorBeginIndex until processorEndIndex) processors(i) = newProcessor(i, connectionQuotas, protocol) 如这个listeners=PLAINTEXT://10.45.4.9:9093,SASL_PLAINTEXT://10.45.4.9:9094定义了两个EndPoint：第一个endpoint的protocol是PLAINTEXT即明文无安全验证，第二个是使用SASL_PLAINTEXT安全验证的。每个endpoint都会创建一定数量(由num.network.threads控制)的processor。 下面再来看看创建Channel的主要逻辑：switch (securityProtocol) &#123; case SSL: ... case SASL_SSL: case SASL_PLAINTEXT: requireNonNullMode(mode, securityProtocol); if (loginType == null) throw new IllegalArgumentException(&quot;`loginType` must be non-null if `securityProtocol` is `&quot; + securityProtocol + &quot;`&quot;); if (mode == Mode.CLIENT &amp;&amp; clientSaslMechanism == null) throw new IllegalArgumentException(&quot;`clientSaslMechanism` must be non-null in client mode if `securityProtocol` is `&quot; + securityProtocol + &quot;`&quot;); channelBuilder = new SaslChannelBuilder(mode, loginType, securityProtocol, clientSaslMechanism, saslHandshakeRequestEnable); break; case PLAINTEXT: channelBuilder = new PlaintextChannelBuilder(); break; default: throw new IllegalArgumentException(&quot;Unexpected securityProtocol &quot; + securityProtocol);&#125; 这里主要关心的是SASL_PLAINTEXT以及PLAINTEXT的处理。 当security.protocol=SASL_PLAINTEXT时Client端创建的Channel中的saslMechanism不能为空。可以看到上面socketServer创建Channel时传过来的saslMechanism字段为空。我们再来看看producer/consumer创建Channel时的代码：String clientSaslMechanism = (String) configs.get(SaslConfigs.SASL_MECHANISM);return ChannelBuilders.create(securityProtocol, Mode.CLIENT, LoginType.CLIENT, configs, clientSaslMechanism, true); 客户端sasl.mechanism默认值为GSSAPI。KafkaChannel构造函数包含四个属性： private final String id;private final TransportLayer transportLayer;private final Authenticator authenticator;private final int maxReceiveSize; 当security.protocol=SASL_PLAINTEXT || PLAINTEXT时，用的都是PlaintextTransportLayer，该类中包含一个Principal：ANONYMOUS，如果kafka开启了权限控制，那么当不安全(security.protocol=PLAINTEXT)的client连接不安全的endpoint时需要为ANONYMOUS用户分配访问权限。Channel的验证工具有两种对应于client和server Note left of SaslClient: SEND_HANDSHAKE_REQUESTNote right of SaslServer: HANDSHAKE_REQUESTSaslClient-&gt;SaslServer: SaslHandshakeRequest (ApiVersion=*,correlationId=*,clientMechanism=*)Note left of SaslClient: RECEIVE_HANDSHAKE_RESPONSENote left of SaslServer: check clientMechanism is enabledSaslServer-&gt;SaslClient: SaslHandshakeResponseNote right of SaslClient: check error code in responseNote left of SaslClient: FAILED or INITALNote right of SaslServer: AUTHENICATE","categories":[],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"producer的回调实现","slug":"producer的回调实现","date":"2017-03-07T05:23:01.000Z","updated":"2018-04-11T05:53:29.968Z","comments":true,"path":"2017/03/07/producer的回调实现/","link":"","permalink":"http://yoursite.com/2017/03/07/producer的回调实现/","excerpt":"","text":"为了方便用户感知发送的情况，kafka producer中提供了callback机制，springkafka中实现了ProducerListener 遇到的问题近期生产环境上由于版本BUG问题导致一段时间内某台broker出现假死的异常状态，在这异常期间内发送到该broker上的消息都失败了。在各个系统中我们实现了一个ProducerListener用于将发送失败的消息写入到Hbase中，方便后续处理。 然而，实际情况是Hbase中(与log中一致，排除写入Hbase的错误)的错误记录不全。 接下来以从上往下的层次顺序解析下Producer callback的运行机制，以及对Exception的处理 ProducerListener首先看下KafkaTemplate的简化UML图在doSend方法中为producer的send方法设置回调函数：protected ListenableFuture&lt;SendResult&lt;K, V&gt;&gt; doSend(final ProducerRecord&lt;K, V&gt; producerRecord) &#123; this.producer.send(producerRecord, new Callback() &#123; public void onCompletion(RecordMetadata metadata, Exception exception) &#123; if(exception == null) &#123; if(KafkaTemplate.this.producerListener != null &amp;&amp; KafkaTemplate.this.producerListener.isInterestedInSuccess()) &#123; KafkaTemplate.this.producerListener.onSuccess(...); &#125; &#125; else &#123; if(KafkaTemplate.this.producerListener != null) &#123; KafkaTemplate.this.producerListener.onError(...,exception); &#125; &#125; &#125; &#125;);&#125; 如果我们在创建KafkaTemplate时没有设置producerListener属性，那么就会使用默认的：LoggingProducerListener。 KafkaProducer之前对KafkaProducer的异步发送机制实现进行过分析，有一个sender线程用于协调消息队列及网络通信的工作，在运行过程中可能发生多种异常需要统一进行处理：private Future&lt;RecordMetadata&gt; doSend(ProducerRecord&lt;K, V&gt; record, Callback callback) &#123; try &#123; Callback interceptCallback = this.interceptors == null ? callback : new InterceptorCallback&lt;&gt;(callback, this.interceptors, tp); RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey, serializedValue, interceptCallback, remainingWaitMs); this.sender.wakeup(); return result.future; //API异常会调用callback的onCompletion方法 &#125;catch (ApiException e) &#123; callback.onCompletion(null, e); this.errors.record(); if (this.interceptors != null) this.interceptors.onSendError(record, tp, e); return new FutureFailure(e); //其他异常直接抛出 &#125; catch (Exception e)&#123; if (this.interceptors != null) this.interceptors.onSendError(record, tp, e); throw e; &#125; interceptCallback将KafkaTemplate注入的ProducerListener以及KafkaProducer配置的拦截器ProducerInterceptors组合在一起，统一对发送的执行结果进行拦截处理。 通过append方法将拦截器配置到每个RecordBatch中public FutureRecordMetadata tryAppend( byte[] key, byte[] value, Callback callback) &#123; ... if (callback != null) thunks.add(new Thunk(callback, future));&#125; Thunk是内部类，将callback于FutureRecordMetadata捆绑在一起。在每个RecordBatch被处理完成的时候(3种情况：1.发送完成；2.失效；3.producer被强制关闭；)会执行绑定的callback方法：public void done(long baseOffset, long timestamp, RuntimeException exception) &#123; for (int i = 0; i &lt; this.thunks.size(); i++) &#123; Thunk thunk = this.thunks.get(i); if (exception == null) &#123; RecordMetadata metadata = new RecordMetadata(...); thunk.callback.onCompletion(metadata, null); &#125; else &#123; thunk.callback.onCompletion(null, exception); &#125; &#125; &#125; 按理来说，这里已经覆盖了所有的情况，为什么现实使用中会有发送失败未记录下来的情况呢？","categories":[],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"Kafka consumer原理剖析","slug":"Kafka consumer原理剖析","date":"2017-03-01T02:00:40.000Z","updated":"2018-04-11T05:52:41.130Z","comments":true,"path":"2017/03/01/Kafka consumer原理剖析/","link":"","permalink":"http://yoursite.com/2017/03/01/Kafka consumer原理剖析/","excerpt":"","text":"Blockquote REF KafkaConsumer API doc Kafka 之 Group 状态变化分析及 Rebalance 过程 Kafka conumser redesign since 0.9.0 趣解reblance consumer的新特性 在 0.9.0.0 之后的 Kafka，出现了几个新变动，一个是在 Server 端增加了 GroupCoordinator 这个角色，另一个较大的变动是将 topic 的 offset 信息由之前存储在 zookeeper 上改为存储到一个特殊的 topic 中（__consumer_offsets）。 __consumer_offsetsconsumer_offsets 是 Kafka 内部使用的一个 topic，专门用来存储 group 消费的情况，默认情况下有50个 partition，每个 partition 三副本，而具体 group 的消费情况要存储到哪一个 partition 上，是根据 abs(GroupId.hashCode()) % NumPartitions 来计算（其中，NumPartitions 是consumer_offsets 的 partition 数，默认是50个）的。 offset Last Commiteed Offset：consumer上一次commit的位置； Current Position：cosumer当前消费到的位置，last coomitted offset 到current position之间的就是当前正被consumer处理的消息。 High Watermark：被成功备份到所有replicas的最新位置，该位置之前的所消息都被认为是安全可消费的。 Log End Offset：Producer 写入到 Kafka 中的最新一条数据的 offset； coordinator机制 kafka server将partiton分配的工作转移到了Client上(Producer中也可以看到)，server保留的是group的分配工作，这样的设计是为了方便client使用灵活的partition分配方案。 coordinator in serverserver上的Coordinator 负责reblance、Offset提交、心跳，实现主要代码在kafka.coordinator.GroupCoordinator.scala 一个consumer group对应一个coordinator coordinator 状态机共有5种状态： Dead：group中没有成员，并且metadata已被移除,这种状态响应各种请求都是一个response： UNKNOWN_MEMBER_ID Empty：Group 没有任何成员，如果所有的 offsets 都过期的话就会变成 Dead，一般当 Group 新创建时是这个状态，也有可能这个 Group 仅仅用于 offset commits 并没有任何成员,该状态至响应JoinGroupRequest Stable：这种状态下，coordinator已经获得了激活的generation，或者目前没有成员，等待第一个joinGroup。该状态还会接受成员的heartbeats。 PreparingRebalance：准备重平衡状态，例如member发生变化 AwaitingSync：所有的joinGroup请求都接受到后，会选举产生一个leader，这个状态就是在等待leader发送partition的分配结果(SyncGroupRequest)。 状态机如下： coordinator in client 根据KafkaConsumer主要方法pollOnce来跟踪client上的coordinator工作过程private Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; pollOnce(long timeout) &#123; coordinator.ensureCoordinatorReady(); if (subscriptions.partitionsAutoAssigned()) coordinator.ensurePartitionAssignment(); if (!subscriptions.hasAllFetchPositions()) updateFetchPositions(this.subscriptions.missingFetchPositions()); long now = time.milliseconds(); client.executeDelayedTasks(now); Map&lt;TopicPartition, List&lt;ConsumerRecord&lt;K, V&gt;&gt;&gt; records = fetcher.fetchedRecords(); if (!records.isEmpty()) return records; fetcher.sendFetches(); client.poll(timeout, now); return fetcher.fetchedRecords();&#125; 第一步、投石问路——确保server端有可用的coordinatorpublic void ensureCoordinatorReady() &#123; //通过与节点建立连接判断coordinator是否存活 while (coordinatorUnknown()) &#123; //发送GroupCoordinatorRequest请求 RequestFuture&lt;Void&gt; future = sendGroupCoordinatorRequest(); client.poll(future); if (future.failed()) &#123; if (future.isRetriable()) client.awaitMetadataUpdate(); else throw future.exception(); &#125; else if (coordinator != null &amp;&amp; client.connectionFailed(coordinator)) &#123; coordinatorDead(); time.sleep(retryBackoffMs); &#125; &#125;&#125; 如果请求有broker响应了，那么将将该节点做为coordinator：this.coordinator = new Node(Integer.MAX_VALUE - groupCoordinatorResponse.node().id(), groupCoordinatorResponse.node().host(), groupCoordinatorResponse.node().port()); 第二步、确保group是可用的首先，对group需要reJoin的情况进行梳理： 有consumer离开当前group，client会发送一个LeaveGroupRequest如： 不再订阅某个topic ConsumerCoordinator执行关闭操作 发送SyncGroupRequest后收到的response异常 发送HeartbeatRequest后收到的response异常，包括：REBALANCE_IN_PROGRESS(正在重平衡),ILLEGAL_GENERATION(generation值不合法),UNKNOWN_MEMBER_ID(未知的成员)public void ensureActiveGroup() &#123; if (!needRejoin()) return; //如果设置了auto commit，那么在rebalance之前先提交，再准备reJoin if (needsJoinPrepare) &#123; onJoinPrepare(generation, memberId); needsJoinPrepare = false; &#125; while (needRejoin()) &#123; ensureCoordinatorReady(); //在reblance执行之前，需要确保所有JoinGroup的请求都被处理掉了，避免频繁的reblance if (client.pendingRequestCount(this.coordinator) &gt; 0) &#123; client.awaitPendingRequests(this.coordinator); continue; &#125; RequestFuture&lt;ByteBuffer&gt; future = sendJoinGroupRequest(); future.addListener(new RequestFutureListener&lt;ByteBuffer&gt;() &#123; @Override public void onSuccess(ByteBuffer value) &#123; onJoinComplete(generation, memberId, protocol, value); needsJoinPrepare = true; heartbeatTask.reset(); &#125; &#125;); client.poll(future); &#125;&#125; JoinGroupRequest中包含的信息有： groupId memberId subscriptions &amp;&amp; PartitionAssignor(默认：RangeAssignor) 第三步、处理JoinGroupResponse这是通过回调函数实现的，具体的是JoinGroupResponseHandler的handle方法：public void handle(JoinGroupResponse joinResponse, RequestFuture&lt;ByteBuffer&gt; future) &#123; Errors error = Errors.forCode(joinResponse.errorCode()); if (error == Errors.NONE) &#123; //记录新的generation AbstractCoordinator.this.generation = joinResponse.generationId(); AbstractCoordinator.this.rejoinNeeded = false; //leader与follower区别对待 if (joinResponse.isLeader()) &#123; onJoinLeader(joinResponse).chain(future); &#125; else &#123; onJoinFollower().chain(future); &#125; &#125; else if &#123; ... &#125;&#125; server的coordinator在收到joinGroupRequest后，会为每个group组选择一个member任命为leader。 leader在收到response后，会进行partition的分配，并且将分配结果发送给server的coordinatorprivate RequestFuture&lt;ByteBuffer&gt; onJoinLeader(JoinGroupResponse joinResponse) &#123; Map&lt;String, ByteBuffer&gt; groupAssignment = performAssignment(joinResponse.leaderId(), joinResponse.groupProtocol(), joinResponse.members()); SyncGroupRequest request = new SyncGroupRequest(groupId, generation, memberId, groupAssignment); return sendSyncGroupRequest(request);&#125; 分区分配的逻辑：protected Map&lt;String, ByteBuffer&gt; performAssignment(String leaderId, String assignmentStrategy, Map&lt;String, ByteBuffer&gt; allSubscriptions) &#123; //获取分配规则(默认range) PartitionAssignor assignor = lookupAssignor(assignmentStrategy); Set&lt;String&gt; allSubscribedTopics = new HashSet&lt;&gt;(); Map&lt;String, Subscription&gt; subscriptions = new HashMap&lt;&gt;(); //获取订阅的topic for (Map.Entry&lt;String, ByteBuffer&gt; subscriptionEntry : allSubscriptions.entrySet()) &#123; Subscription subscription = ConsumerProtocol.deserializeSubscription(subscriptionEntry.getValue()); subscriptions.put(subscriptionEntry.getKey(), subscription); allSubscribedTopics.addAll(subscription.topics()); &#125; this.subscriptions.groupSubscribe(allSubscribedTopics); metadata.setTopics(this.subscriptions.groupSubscription()); //对每个订阅的topic进行分区分配 Map&lt;String, Assignment&gt; assignment = assignor.assign(metadata.fetch(), subscriptions); Map&lt;String, ByteBuffer&gt; groupAssignment = new HashMap&lt;&gt;(); for (Map.Entry&lt;String, Assignment&gt; assignmentEntry : assignment.entrySet()) &#123; ByteBuffer buffer = ConsumerProtocol.serializeAssignment(assignmentEntry.getValue()); groupAssignment.put(assignmentEntry.getKey(), buffer); &#125; return groupAssignment;&#125; follower只需要发送一个不包含分区结果的SyncGroupRequestprivate RequestFuture&lt;ByteBuffer&gt; onJoinFollower() &#123; SyncGroupRequest request = new SyncGroupRequest(groupId, generation, memberId, Collections.&lt;String, ByteBuffer&gt;emptyMap()); return sendSyncGroupRequest(request);&#125; 关闭KafkaListnerContainer时发生了些什么一共三个操作：if(this.listenerInvokerFuture != null) &#123; this.stopInvokerAndCommitManualAcks();&#125;try &#123; this.consumer.unsubscribe();&#125; catch (WakeupException var8) &#123; ;&#125;this.consumer.close(); 主要看unsubscribe方法：this.subscriptions.unsubscribe();this.coordinator.maybeLeaveGroup();this.metadata.needMetadataForAllTopics(false); 首先取消了所有订阅 然后发送一个LeaveGroupRequest，并且将memberId设为UNKNOWN,needRejoin设为true 当所有member离开时，server的coordinator进入Empty状态 小实验创建两个ListenerContainer，订阅同一个topic(“test” with partitions=6)，并且在同一个group内：ConcurrentMessageListenerContainer testContainer = new ContainerBuilder() // .setTopic(&quot;kafka.scanAllBackup&quot;) .setTopic(&quot;test&quot;) .setGroupId(&quot;g1&quot;) .setListenerName(&quot;testListener&quot;) .setBeanName(&quot;testContainer&quot;)...ConcurrentMessageListenerContainer secondContainer = new ContainerBuilder() // .setTopic(&quot;kafka.scanAllBackup&quot;) .setTopic(&quot;test&quot;) .setGroupId(&quot;g1&quot;) .setListenerName(&quot;testListener&quot;) .setBeanName(&quot;secondContainer&quot;) 实验结果开启第一个Container 此时的generation = 1，分配的分区数为6开启第二个Container 因为有新的member加入，因此触发了Rebalance，根据Range分配规则，每个consumer获得3个分区 简述下Range Assignor规则：假如topic有N个分区(按number排序)，group组内有M个consumer(按字典序排列)订阅，那么就现将分区分成M份，每份N/M个，如果不能整除，就将余数(N%M)分配给前N%M个consumer 关闭第一个Container有member离开group，再次触发Reblance，第二个container独享6个分区 实验二在使用kafka的时候有个现象：如果将正在消费的consumer关闭、重启，那么在短时间内他是无法接收到消息的，从日志上看得话就是server coordinator没有为这个consumer分配分区，为了详解这种机制，我将发送JoinGroup的debug信息输出。测试用例同上开启第一个container在6分09秒发送了一个joinGroup请求，但是并没有得到反馈。 g1这个group在server中的generation=1，因此新的joinGroup请求进来后，server进入PreparingRebalance状态。 开启第二个Container，关闭第一个container 发送了第二个joinGroup请求，并没有马上收到反馈，在6分29秒关闭了第一个container，经过了96s后，收到了反馈，并且指定leader为client2(也就是当前的consumer)，client1是member，成功分配到了3个分区。在10分06秒的时候，server再次执行了重平衡，client2再次发送了joinGroup请求，马上得到了反馈，并且这次独享6个分区。 产生这次重平衡的原因是：8分05秒server反馈了joinGroup请求，session_timeout设置的是两分钟，在10分05秒的时候，server依然未收到client1的heartbeat，因此触发了重平衡 server.log[2017-03-02 19:06:03,197] INFO [GroupCoordinator 2]: Stabilized group g1 generation 1 (kafka.coordinator.GroupCoordinator)[2017-03-02 19:06:03,201] INFO [GroupCoordinator 2]: Assignment received from leader for group g1 for generation 1 (kafka.coordinator.GroupCoordinator)[2017-03-02 19:06:10,351] INFO [GroupCoordinator 2]: Preparing to restabilize group g1 with old generation 1 (kafka.coordinator.GroupCoordinator)[2017-03-02 19:08:06,504] INFO [GroupCoordinator 2]: Stabilized group g1 generation 2 (kafka.coordinator.GroupCoordinator)[2017-03-02 19:08:06,511] INFO [GroupCoordinator 2]: Assignment received from leader for group g1 for generation 2 (kafka.coordinator.GroupCoordinator)[2017-03-02 19:10:06,506] INFO [GroupCoordinator 2]: Preparing to restabilize group g1 with old generation 2 (kafka.coordinator.GroupCoordinator)[2017-03-02 19:10:06,966] INFO [GroupCoordinator 2]: Stabilized group g1 generation 3 (kafka.coordinator.GroupCoordinator)[2017-03-02 19:10:06,970] INFO [GroupCoordinator 2]: Assignment received from leader for group g1 for generation 3 (kafka.coordinator.GroupCoordinator)[2017-03-02 19:10:51,173] INFO [GroupCoordinator 2]: Preparing to restabilize group g1 with old generation 3 (kafka.coordinator.GroupCoordinator)[2017-03-02 19:10:51,175] INFO [GroupCoordinator 2]: Group g1 generation 3 is dead and removed (kafka.coordinator.GroupCoordinator) 6分03秒，server收到来自leader的syncGroup请求，coordinator进入Stable状态。 随后，非正常关闭container，所有member离开了group，coordinator进入Empty状态 coordinator无法收到members的心跳 6分10秒，client重启，并发送了joinGroup请求，memberId为UNKNOWN,server进入PreparingRebalance状态 疑点： coordinator在收到client1的leaveGroup请求后为啥还会响应其joinGroup请求嘞？ coordinator因为没有感知到client1的离开，所以才会长时间等待","categories":[],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"Metadata详解","slug":"Metadata详解","date":"2017-02-28T05:50:23.000Z","updated":"2018-04-11T05:52:52.233Z","comments":true,"path":"2017/02/28/Metadata详解/","link":"","permalink":"http://yoursite.com/2017/02/28/Metadata详解/","excerpt":"","text":"探究org.apache.kafka.clients中Metadata的数据结构、更新及获取原理 ref Metadata是为producer及consumer服务的，在producer和consumer创建的时候都会创metadata：this.metadata = new Metadata(retryBackoffMs, config.getLong(ConsumerConfig.METADATA_MAX_AGE_CONFIG));this.metadata = new Metadata(retryBackoffMs, config.getLong(ProducerConfig.METADATA_MAX_AGE_CONFIG)); 成员变量 refreshBackoffMs：metadata的最短刷新间隔，避免频繁的Poll操作，默认100ms metadataExpireMs：在下次更新前，metadata保存的最长时间，默认5min version：每次更新一次metadata都会将version值增加1 lastRefreshMs：上次更新时间，也记录更新失败时间 lastSuccessfulRefreshMs：上次成功更新时间 cluster：记录集群中节点、partitionInfo、topic之间的关系，只是个子集，因为Metadata初始化的时候，cluster也是初始化为空的 listeners：自定义的接口，用于监听Metadata更新，在ConsumerCoordinator有使用到 needMetadataForAllTopics：是否需要cluster中所有topic的metadata，默认为false 方法1. timeToNextUpdate该方法用于计算下一次刷新metadata的的时间间隔(ms)public synchronized long timeToNextUpdate(long nowMs) &#123; //距离时效还有多长时间 long timeToExpire = needUpdate ? 0 : Math.max(this.lastSuccessfulRefreshMs + this.metadataExpireMs - nowMs, 0); //距离下一次允许刷新的时间 long timeToAllowUpdate = this.lastRefreshMs + this.refreshBackoffMs - nowMs; return Math.max(timeToExpire, timeToAllowUpdate);&#125; Metadata的使用是线程安全的。 2. awaitUpdatepublic synchronized void awaitUpdate(final int lastVersion, final long maxWaitMs) throws InterruptedException &#123; ... long begin = System.currentTimeMillis(); long remainingWaitMs = maxWaitMs; /*循环等待version值超过当前version值,时间耗尽就退出*/ while (this.version &lt;= lastVersion) &#123; if (remainingWaitMs != 0) wait(remainingWaitMs); long elapsed = System.currentTimeMillis() - begin; if (elapsed &gt;= maxWaitMs) throw new TimeoutException(&quot;Failed to update metadata after &quot; + maxWaitMs + &quot; ms.&quot;); remainingWaitMs = maxWaitMs - elapsed; &#125;&#125; 3. updatepublic synchronized void update(Cluster cluster, long now) &#123; this.needUpdate = false; this.lastRefreshMs = now; this.lastSuccessfulRefreshMs = now; this.version += 1; //如果有人监听了metadata的更新，通知他们 for (Listener listener: listeners) listener.onMetadataUpdate(cluster); //新的cluster覆盖旧的cluster this.cluster = this.needMetadataForAllTopics ? getClusterForCurrentTopics(cluster) : cluster; notifyAll(); //通知所有的阻塞的线程(调用了wait的线程)&#125; producer获取metadata时效图如下：","categories":[],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"kafka producer原理梳理","slug":"kafka producer原理梳理","date":"2017-02-28T02:22:00.000Z","updated":"2018-04-11T05:53:16.280Z","comments":true,"path":"2017/02/28/kafka producer原理梳理/","link":"","permalink":"http://yoursite.com/2017/02/28/kafka producer原理梳理/","excerpt":"","text":"从Kafka 0.8.2开始，发布了一套新的Java版的client api,KafkaProducer/KafkaConsumer，替代之前的scala版的api。 REFKafka： Producer （0.10.0.0）Kafka源码分析 Producer客户端(超详细) 重要配置项说明 linger.ms：这是在send的过程中人为设置的一个delay，目的是将尽可能多的消息放到一个batch中，这样能减少发送的次数； max.block.ms：如果buffer满了或者无法获取到metadata，那么将阻塞KafkaProducer.send()与partitionFor()这两个方法，为了防止无限等待，这里设置了一个最长等待时间,默认为60s,超出这个时间的消息就不会被发送了； request.timeout.ms：连接超时时间，设置为30s； send下面是KafkaProducer执行send操作的时序图：采用的是一种Non-block的工作方式，提供一个callback,调用send后，可以继续发送消息而不用等待。当有结果返回时，callback会被自动通知执行。public Future&lt;RecordMetadata&gt; doSend(ProducerRecord&lt;K, V&gt; record, Callback callback) &#123; // first make sure the metadata for the topic is available long waitedOnMetadataMs = waitOnMetadata(record.topic(), this.maxBlockTimeMs); long remainingWaitMs = Math.max(0, this.maxBlockTimeMs - waitedOnMetadataMs); // 序列化key和value byte[] serializedKey= keySerializer.serialize(record.topic(), record.key()); byte[] serializedValue = valueSerializer.serialize(record.topic(), record.value()); // 根据key选择Partition int partition = partition(record, serializedKey, serializedValue, metadata.fetch()); TopicPartition tp = new TopicPartition(record.topic(), partition); RecordAccumulator.RecordAppendResult result = accumulator.append(tp, serializedKey, serializedValue, callback, remainingWaitMs); // 在每次追加一条消息到收集器之后,都要判断是否满了.如果满了,就执行一次Sender操作,通知Sender将这批数据发送到Kafka if (result.batchIsFull || result.newBatchCreated) this.sender.wakeup(); return result.future;&#125; RecordAccumulatorkafka消息的异步发送是依靠消息缓存实现的，RecordAccumulator扮演的就是这个角色，它创建了一个ConcurrentMap&lt;TopicPartition, Deque&lt;RecordBatch&gt;&gt;类型的缓存结构，每条消息会被放到对应的双端队列中。 appendpublic RecordAppendResult append(TopicPartition tp, long timestamp, byte[] key, byte[] value, Callback callback, long maxTimeToBlock) throws InterruptedException &#123; //用于记录当前等待处理的batch数量 appendsInProgress.incrementAndGet(); try &#123; // 有可用的dq就试着将消息入队 Deque&lt;RecordBatch&gt; dq = getOrCreateDeque(tp); synchronized (dq) &#123; RecordBatch last = dq.peekLast(); if (last != null) &#123; FutureRecordMetadata future = last.tryAppend(timestamp, key, value, callback, time.milliseconds()); if (future != null) return new RecordAppendResult(future, dq.size() &gt; 1 || last.records.isFull(), false); &#125; &#125; // 无法放到之前的dq，那么就分配空间然后创建dq int size = Math.max(this.batchSize, Records.LOG_OVERHEAD + Record.recordSize(key, value)); ByteBuffer buffer = free.allocate(size, maxTimeToBlock); synchronized (dq) &#123; MemoryRecords records = MemoryRecords.emptyRecords(buffer, compression, this.batchSize); RecordBatch batch = new RecordBatch(tp, records, time.milliseconds()); FutureRecordMetadata future = Utils.notNull(batch.tryAppend(timestamp, key, value, callback, time.milliseconds())); dq.addLast(batch); incomplete.add(batch); return new RecordAppendResult(future, dq.size() &gt; 1 || batch.records.isFull(), true); &#125; &#125; finally &#123; appendsInProgress.decrementAndGet(); &#125;&#125; 为了实现并发，对每个队列的操作都放在同步块中操作 新创建了一个RecordBatch，或者当前的RecordBatch的buffer被填满了，那么就可以发车 (唤醒Sender)了 ready 找出每个topic-partition对应的leader，并判断发送条件是否成熟public ReadyCheckResult ready(Cluster cluster, long nowMs) &#123; Set&lt;Node&gt; readyNodes = new HashSet&lt;Node&gt;(); for (Map.Entry&lt;TopicPartition, Deque&lt;RecordBatch&gt;&gt; entry : this.batches.entrySet()) &#123; TopicPartition part = entry.getKey(); Deque&lt;RecordBatch&gt; deque = entry.getValue(); Node leader = cluster.leaderFor(part); if (leader == null) &#123; unknownLeadersExist = true; &#125; else if (!readyNodes.contains(leader) &amp;&amp; !muted.contains(part)) &#123; synchronized (deque) &#123; RecordBatch batch = deque.peekFirst(); if (batch != null) &#123; ... boolean sendable = full || expired || exhausted || closed || flushInProgress(); if (sendable &amp;&amp; !backingOff) &#123; readyNodes.add(leader); &#125; else &#123; nextReadyCheckDelayMs = Math.min(timeLeftMs, nextReadyCheckDelayMs); &#125; &#125; &#125; &#125; &#125; return new ReadyCheckResult(readyNodes, nextReadyCheckDelayMs, unknownLeadersExist);&#125; drain 在ready环节已经找出所有的ready nodes，那么接下来就将batchs中的RecordBatch按照node进行分组，方便后续的发送 Request &amp;&amp; Response 下面要探究的是如何将RecordBatch转换成server端能理解的请求，以及收到server的响应后如何进行处理。 首先，将发往相同broker、topic-partition的RecordBatch组成一个ProduceRequest 根据ProduceRequest进而组成一个用于发送的RequestSend 在handleProduceResponse方法中实现了对ClientResponse的处理，在这里会对batch做done操作，细节在producer回调中有阐述。 根据上面的处理方法实现了回调方法，进而完成了ClientRequest的组建工作 ProduceRequest request = new ProduceRequest(acks, timeout, produceRecordsByPartition);RequestSend send = new RequestSend(Integer.toString(destination), this.client.nextRequestHeader(ApiKeys.PRODUCE), request.toStruct());RequestCompletionHandler callback = new RequestCompletionHandler() &#123; public void onComplete(ClientResponse response) &#123; handleProduceResponse(response, recordsByPartition, time.milliseconds()); &#125;&#125;;return new ClientRequest(now, acks != 0, send, callback); 回调函数是在NetworkClient层被调用的，具体的是client.poll()中：for (ClientResponse response : responses) &#123; if (response.request().hasCallback()) &#123; try &#123; response.request().callback().onComplete(response); &#125; catch (Exception e) &#123; log.error(&quot;Uncaught error in request completion:&quot;, e); &#125; &#125;&#125; NetworkClient NetworkClient是kafka客户端实现网络连接、数据读写的。是通过Java NIO实现的，并且实现了自己的Selector与KafkaChannel 连接在Sender的run方法中创建ClientRequest之前需要先筛选出可连接的节点，这里调用的是NetworkClient的ready方法：if (connectionStates.canConnect(node.idString(), now)) initiateConnect(node, now); 然后调用Selector的connect方法： 开启一个SocketChannel SocketChannel socketChannel = SocketChannel.open();socketChannel.configureBlocking(false);Socket socket = socketChannel.socket();socket.setKeepAlive(true); 将创建的Channel注册在nioSelector上，监听事件为：OP_CONNECT 创建KafkaChannel,并与brokerId绑定KafkaChannel channel = channelBuilder.buildChannel(id, key, maxReceiveSize); key.attach(channel); this.channels.put(id, channel); 因为实现的是非阻塞模式的，因此connect方法在连接成功建立之前就会返回的。为了确保连接成功，需要调用KafkaChannel的finishConnect方法 public boolean finishConnect() throws IOException &#123; boolean connected = socketChannel.finishConnect(); if (connected) key.interestOps(key.interestOps() &amp; ~SelectionKey.OP_CONNECT | SelectionKey.OP_READ); return connected;&#125; 在连接成功后就注册了OP_READ。为什么不在发送请求的时候注册嘞，因为一来响应什么时候到我们是无法预料的，二来有些请求并不要求响应。 发送在组建完ClientRequest后，要调用Selector的send操作，被发送的主体是RequestSend：public void send(Send send) &#123; KafkaChannel channel = channelOrFail(send.destination()); channel.setSend(send);&#125;private KafkaChannel channelOrFail(String id) &#123; KafkaChannel channel = this.channels.get(id);&#125; 需要注意的是： 每个KafkaChannel上只有一个RequestSend，无法加塞，必须在之前的被发送掉后才能上车 setSend的操作会注册OP_WRITE，然后在发送完成后，会取消掉OP_WRITE //设置发送的主体public void setSend(Send send) &#123; if (this.send != null) throw new IllegalStateException(&quot;Attempt to begin a send operation with prior send operation still in progress.&quot;); this.send = send; this.transportLayer.addInterestOps(SelectionKey.OP_WRITE);&#125;//send完成后取消OP_WRITEprivate boolean send(Send send) throws IOException &#123; send.writeTo(transportLayer); if (send.completed()) transportLayer.removeInterestOps(SelectionKey.OP_WRITE); return send.completed();&#125; poll轮询 上面的setSend、write、send的操作如何组织起来呢，这就是poll的工作了。 简单来说就是nioSelector执行一个select操作，然后遍历SelectionKey，如果有我们感兴趣的操作，就对相应的Channel进行read、write之类的操作。 遍历获取有事件发生的ChannelIterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator();//遍历获取每个事件上的Channelwhile (iterator.hasNext()) &#123; SelectionKey key = iterator.next(); iterator.remove(); KafkaChannel channel = channel(key); if (channel.finishConnect()) &#123; this.connected.add(channel.id()); &#125; else continue;&#125; read from KafkaChannelif (channel.ready() &amp;&amp; key.isReadable() &amp;&amp; !hasStagedReceive(channel)) &#123; NetworkReceive networkReceive; while ((networkReceive = channel.read()) != null) addToStagedReceives(channel, networkReceive);&#125; key.isReadable()只有在Channel监听Read事件，并且Channel有数据写入时才成立 在完成读操作后，会将NetworkReceive添加到队列：completedReceives中write to KafkaChannelif (channel.ready() &amp;&amp; key.isWritable()) &#123; Send send = channel.write(); if (send != null) &#123; this.completedSends.add(send); this.sensors.recordBytesSent(channel.id(), send.size()); &#125;&#125; 不同于read操作时使用了while循环来确保读取完毕，write操作是一次性的，如果发送完毕，就去除OP_WRITE事件，并且将Send添加到队列completedSends中；否则就将不取消,然后在后面的循环中继续执行写操作，直至写完为止 NetworkClient.poll 下面把目光拉回到NetworkClient中，来看看执行完selector的poll操作之后，是如何进一步处理的。 ClientRequest在被NetworkClient层执行发送操作的时候，会被添加到inFlightRequests中，这个名字很形象——正在飞行中的请求，指代正在发送或者等待响应的请求的集合。该集合中将ClientRequest按照目的节点进行分组，相同目的节点的保存在同一个双端队列中。 handleCompletedSendsfor (Send send : this.selector.completedSends()) &#123; ClientRequest request = this.inFlightRequests.lastSent(send.destination()); if (!request.expectResponse()) &#123; this.inFlightRequests.completeLastSent(send.destination()); responses.add(new ClientResponse(request, now, false, null)); &#125;&#125; 对于不要求响应的请求，将发送完成的RequestSend对应的ClientRequest从inFlightRequests中移除，直接组建一个body为空的response。 handleCompletedReceivesfor (NetworkReceive receive : this.selector.completedReceives()) &#123; String source = receive.source(); ClientRequest req = inFlightRequests.completeNext(source); Struct body = parseResponse(receive.payload(), req.request().header()); if (!metadataUpdater.maybeHandleCompletedReceive(req, now, body)) responses.add(new ClientResponse(req, now, false, body));&#125; 根据接收到的源地址，移除inFlightRequests中对应的ClientRequest，并且根据收到的内容组建response producer消息发送过程","categories":[],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]}]}