{"meta":{"title":"天外飞猪的博客","subtitle":null,"description":"人为什么越长大越孤单？\n答:内心中有秘密,无法诉说\n","author":"fbZhu","url":"http://yoursite.com"},"pages":[{"title":"tags","date":"2018-04-04T07:35:47.000Z","updated":"2018-04-04T07:44:50.377Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"kafka消息","slug":"kafka消息","date":"2018-04-11T05:39:08.000Z","updated":"2018-04-11T05:43:20.583Z","comments":true,"path":"2018/04/11/kafka消息/","link":"","permalink":"http://yoursite.com/2018/04/11/kafka消息/","excerpt":"","text":"带着以下两点疑问，进行kafka server的Log管理源码的分析： producer遇到 NOT_LEADER_EXCEPTION 是在何时产生的 消息是如何在ISR中备份的 下面以从上往下的方式对一条消息写入磁盘的全链路进行分析 KafkaApis kafka apis反映出kafka broker server可以提供哪些服务，broker server主要和producer，consumer，controller有交互，搞清这些api就清楚了broker server的所有行为 handleProducerRequest 该方法用于处理Client的producer请求，ApiKeys = 0 从 RequestChannel 中获取请求，然后根据acks规则进行反馈 写入磁盘的动作在replicaManager.appendRecords中完成 ack规则 acks 规则 0 producer不需要等待ack,server收到消息后直接反馈 1 leader成功写入后反馈给producer -1 (kafka-client中配置为&quot;all&quot;) 在ISR中所有replicas都写入消息后才进行反馈 ReplicaManager.appendMessages 先将消息写入leader的log中(正常情况就是当前这个broker) 将消息写到ISR的其他备份中 超时或者ack规则满足时进行反馈操作(执行回调函数：responseCallback) //写到leader的logval localProduceResults = appendToLocalLog(internalTopicsAllowed, entriesPerPartition, requiredAcks)if (delayedRequestRequired(requiredAcks, entriesPerPartition, localProduceResults)) &#123;//acks=-1时需要创建 delayedProduce实现消息的备份val produceMetadata = ProduceMetadata(requiredAcks, produceStatus)val delayedProduce = new DelayedProduce(timeout, produceMetadata, this, responseCallback)val producerRequestKeys = entriesPerPartition.keys.map(new TopicPartitionOperationKey(_)).toSeqdelayedProducePurgatory.tryCompleteElseWatch(delayedProduce, producerRequestKeys)&#125; else &#123;val produceResponseStatus = produceStatus.mapValues(status =&gt; status.responseStatus)responseCallback(produceResponseStatus)&#125; ReplicaManager.appendToLocalLog 当topic为内部topic(即__consumer_offsets)，并且不允许往内部类中写消息时，抛出 InvalidTopicException val info = partitionOpt match &#123; case Some(partition) =&gt; partition.appendRecordsToLeader(records, requiredAcks) case None =&gt; throw new UnknownTopicOrPartitionException(&quot;Partition %s doesn&apos;t exist on %d&quot; .format(topicPartition, localBrokerId))&#125; Partition.appendRecordsToLeader判断当前broker是否是parition的leaderdef getReplica(replicaId: Int = localBrokerId): Option[Replica] = Option(assignedReplicaMap.get(replicaId))def leaderReplicaIfLocal: Option[Replica] = leaderReplicaIdOpt.filter(_ == localBrokerId).flatMap(getReplica) assignedReplicaMap：用于存放每个partition对应的leader已经replicas 通过比较leaderId与localBrokerId，判断当前broker是否就是leader 如果不满足，那么将抛出NotLeaderForPartitionException 备份数不满足条件的消息不会写入 val log = leaderReplica.log.get val minIsr = log.config.minInSyncReplicas val inSyncSize = inSyncReplicas.size// acks为all的时候才会进行判断 if (inSyncSize &lt; minIsr &amp;&amp; requiredAcks == -1) &#123; throw new NotEnoughReplicasException(&quot;Number of insync replicas for partition %s is [%d], below required minimum [%d]&quot; .format(topicPartition, inSyncSize, minIsr)) &#125; Log.append 返回的格式为LogAppendInfo,包含第一条及最后一条offset信息 找到该Partition在当前broker上面最新的segment，如果塞不进去 就新建一个segment 将消息添加到segment中 更新segment的LogEndOffset为最新添加消息的lastOffset + 1ByteBufferMessageSetappend方法中传入的消息集的数据结构为ByteBufferMessageSet (注：在0.10.2.0版本后引入新的结构：MemoryRecords)，父类为Messageset,其结构如下图所示： 一个有效的MessageSet的最小长度为12字节 Message的组成Message在magic不同的情况下有不同的结构：迭代器的实现internalIterator是ByteBufferMessageSet实现的迭代器，迭代单位是MessageAndOffset magic的值是由server中Log的配置属性：message.format.version决定的，0.10.0之前的版本的magic值为0，之后的版本为1 迭代的过程也是对消息的有效性的检验过程： ByteBuffer(对应MessageSet)的长度是否&lt; 12 消息体(对应Message)的长度是否 &lt; 魔术为0时Message的头部长度(4+1+1+8+4 = 18) ByteBuffer的长度是否&lt;消息体的长度(否则就表明消息不完整) 满足以上条件的消息一定是无法继续迭代的 由于消息的载体实现的是ByteBuffer，那我们就从Buffer的操作的角度来看看message和offset是如何被迭代取出来的： 假设当前接收到一个新的ByteBuffer，下面进行迭代： 获取buffer的片段(第一次算是拷贝)：topIter = buffer.slice() 获取offset(获取前八个字节)： offset = topIter.getLong() 获取size(获取紧接着的四个字节)：size = topIter.getInt() 获取message(当前position指向message的开始位置，截取后续size大小的就可以得到message)：message = topIter.slice; message.limit(size) 将topIter的position指向下一条MessageSet: topIter.position(topIter.position + size) LogAppendInfo的生成LogAppendInfo主要包含四个属性，用于描述message set: firstOffest：第一条消息的offset: lastOffset：最后一条消息的offset: maxTimestamp：消息里面包含的最大时间戳: offsetOfMaxTimestamp：最大时间戳消息的offset analyzeAndValidateMessageSet方法实现了LogAppendInfo的生成，根据上面提到的迭代器对MessageSet中的消息进行迭代处理，找出并记录offset和timestamp信息，此外也对每条消息进行检验： 每条消息的大小不能超过max.message.bytes所定义的 每条消息必须通过循环冗余校验 消息的进一步校验对消息的进一步校验及转化是在validateMessagesAndAssignOffsets方法中完成的。该方法的参数中涉及到一些概念： 1.topic清理策略log.cleanup.policy配置项控制着消息在segment中持久化的策略，目前有两种策略供选择：delete和compact，默认选项为delte。 delete的策略很好理解，就是当segment时间或者大小到期了就删除。 compact的策略是为了满足系统灾后恢复的需求，该选项是针对topic的，比如存在某个topic：email_topic用于存储用户变更的email信息，key=userId,value=emailAddress，compact操作就是在日志删除过程中保留每个userId最新的数据，如果系统崩溃了也能通过该topic获得用户最新修改的email地址。下面的图很好的诠释了这种操作： 2. 版本与magicValue 由于kafka的版本更新速度比较快，为了能让新的server版本兼容老的client版本以及server的滚动升级的实现，提供了message.format.version配置项定义consumer及Producer的API版本。 不同的API版本对应不同的magicValue，其中0.9.0.X版本之前(包括该版本)的magicValue未0，之后的都为1 当前我们生产环境使用的API版本为0.10.0.0，server的版本为0.10.1.1 3. 解析非压缩消息 producer可以选择是否对消息进行压缩 message.timestamp.type：时间戳类型: CreateTime：消息的创建时间&lt;默认值&gt;: LogAppendTime：添加到log的时间 message.timestamp.difference.max.ms：最大时间间隔,表示收到的消息中的时间戳与当前时间的差的最大容忍值。 对非压缩消息的进一步处理的过程依然是ByteBuffer的操作过程：/*主要目的是获取maxTimestamp和offsetOfMaxTimestamp*/var messagePosition = 0var maxTimestamp = Message.NoTimestampvar offsetOfMaxTimestamp = -1L//将position位置存到mark中buffer.mark()while (messagePosition &lt; sizeInBytes - MessageSet.LogOverhead) &#123; buffer.position(messagePosition) //offsetCounter是server维护的下一个offset的值 buffer.putLong(offsetCounter.getAndIncrement()) val messageSize = buffer.getInt() val messageBuffer = buffer.slice() messageBuffer.limit(messageSize) val message = new Message(messageBuffer) //以上的操作能获取到MessageSet中的一条message if (message.magic &gt; Message.MagicValue_V0) &#123; validateTimestamp(message, now, timestampType, timestampDiffMaxMs) if (message.timestamp &gt; maxTimestamp) &#123; maxTimestamp = message.timestamp offsetOfMaxTimestamp = offsetCounter.value - 1 &#125; &#125; //将buffer的position移到后一条消息的头部 messagePosition += MessageSet.LogOverhead + messageSize&#125;//根据mark恢复positionbuffer.reset() 经过上面的操作，MessageSet中的offset被server重新设置了，并且maxTimestamp之类的信息重新收集了。这些信息在append操作中会被使用：validMessages = validateAndOffsetAssignResult.validatedMessagesappendInfo.maxTimestamp = validateAndOffsetAssignResult.maxTimestampappendInfo.offsetOfMaxTimestamp = validateAndOffsetAssignResult.offsetOfMaxTimestampappendInfo.lastOffset = offset.value - 1 其中：: validMessages就是处理完后的MessageSet: offset是上面使用到的offsetCounter，即下一个offset值。为什么要-1?因为上面执行了getAndIncrement()操作，因此当前的offset指向的依然是下一个offset值 4.压缩消息的处理 producer的压缩策略必须与broker一致，如果不匹配那么将不会解压缩消息 以下几种情况不会对压缩消息进行解压处理： topic指定了压缩策略，但是发送的消息中没有key(会报错) 消息体与server的magic值不一致 找到合适的segment 一个topic由多个parition组成，每个partition又存在多个segment 每个segment的大小由log.segment.bytes控制,下面是segment大小设置为1024的broker上某个partiton的Log情况：[test-0]$ du -smh *0 00000000000000017699.index4.0K 00000000000000017699.log4.0K 00000000000000017699.timeindex0 00000000000000017724.index4.0K 00000000000000017724.log0 00000000000000017724.timeindex 每个log的命名规则是取该log中 下一个 offset的值(logEndOffset); 以index结尾的offset index文件的作用是将offset映射到物理文件中 timeindex文件将时间戳与segment中的逻辑offset联系起来 满足以下几个条件之一时会创建新的segment： 当前segment容不下最新的消息 当前segment非空，并且达到了log.roll.hours的时间 offset 或者 time index满了 下面是写消息时创建出新的segment时server的输出日志：[2017-04-05 17:14:29,776] DEBUG Rolling new log segment in test-11 (log_size = 1006/1024&#125;, index_size = 0/1310720, time_index_size = 1/873813, inactive_time_ms = 184193/604800000). (kafka.log.Log) 将消息添加到LogSegment中LogSegment的参数主要有：: log：File类型的MessageSet，该Set中包含一个FileChannel，能够从ByteBuffer中读取数据: index: OffsetIndex，逻辑Offset到物理文件位置的索引: timeIndex：TimeIndex，时间戳到物理位置的索引: baseOffset：第一个offset 写消息的操作：将AppendInfo中的消息写入到LogSegment中的FileChannel中def writeFullyTo(channel: GatheringByteChannel): Int = &#123; buffer.mark() var written = 0 while (written &lt; sizeInBytes) written += channel.write(buffer) buffer.reset() written&#125; _size.getAndAdd(written) FileMessageSet的search操作根据offset或者时间戳是从Log中读取消息的常见方法。FileMessageSet提供对应的两个方法：searchForOffsetWithSize和searchForTimestamp。前者是从FileMessageSet的给定位置往后搜索第一个大于等于目标offset的消息，返回的是Offset&amp;Position，后者是从给定位置往后搜索第一个时间戳大于等于目标时间戳的消息，返回Timestamp&amp;Offset。 下图描述的是从0开始搜索offset≥1003的消息： 写OffsetIndexOffsetIndex中并不会记录所有Offset的映射关系，写入Index的时机由index.interval.bytes参数(default：4096)控制，当segment中积累的消息数量大于该参数时，会将此次写入segment中的MessageSet的第一个消息的offset写入OffsetIndex中：if(bytesSinceLastIndexEntry &gt; indexIntervalBytes) &#123; index.append(firstOffset, physicalPosition) timeIndex.maybeAppend(maxTimestampSoFar, offsetOfMaxTimestamp) bytesSinceLastIndexEntry = 0&#125;bytesSinceLastIndexEntry += messages.sizeInBytes index.append的具体操作如下：if (_entries == 0 || offset &gt; _lastOffset) &#123; mmap.putInt((offset - baseOffset).toInt) mmap.putInt(position) _entries += 1 _lastOffset = offset&#125; 上面的操作是将offset相对这个Segmet的baseOffset的偏移值以及物理地址填入到OffsetIndex中定义的MappedByteBuffer。 之所以使用相对偏移值是出于节省存储空间的考虑，相对偏移值只需要4位空间就能存储，而MessageSet中的offset占8位。 写TimeIndex在每次执行append操作时，TimeIndex记录的是最大时间戳及其对应的offset的索引。if (timestamp &gt; lastEntry.timestamp) &#123; mmap.putLong(timestamp) mmap.putInt((offset - baseOffset).toInt) _entries += 1&#125; 写入Buffer中的是时间戳以及相对偏移量 更新LogEndOffset上面的分析中提到过每个Log都维护了一个记录下一个offset的变量——nextOffsetMetadata,该变量是LogOffsetMetadata类型的：: messageOffset：绝对偏移值: segmentBaseOffset：LogSegment的baseOffset值: relativePositionInSegment：LogSegment的大小(字节数)，根据字节数可以定位到这条消息在segment中的物理位置 每次append操作都会执行：nextOffsetMetadata = new LogOffsetMetadata(messageOffset, activeSegment.baseOffset, activeSegment.size.toInt)其中： messageOffset为 AppendInfo.lastOffset+1 activeSegment是当前可用的segment activeSegment.size由_size.get()，这个_size正是在上面往segment中写消息时进行更新的，每次增加的值是写入channel中的字节数。 下面这张图生动描述了这个更新的操作： 绿色的代表activeSegment，当前的nextOffsetMetadata为10(指的是messageOffset) 写入10条消息后，nextOffsetMetadata更新为21 再次写入10条消息后，更新为31 再来10条消息，无法写入，执行roll操作新建一个segment,messageOffset值未改变，不过activeSegment变化了 将10条消息写入新的segment中，更新为41","categories":[],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"Kafka Coordinator实现细节","slug":"Kafka-Coordinator实现细节","date":"2018-04-04T07:29:55.000Z","updated":"2018-04-04T07:44:07.656Z","comments":true,"path":"2018/04/04/Kafka-Coordinator实现细节/","link":"","permalink":"http://yoursite.com/2018/04/04/Kafka-Coordinator实现细节/","excerpt":"","text":"GroupCoordinator 每个kafka server在启动的时候会创建一个GroupCoordinator用于管理group以及consumer的offset fetch/commit 在创建GroupCoordinator实例时不仅需要brokerId、group以及offset config，还需要传入replicaManager，其作用是 GroupMetadataManagerGroupMetadataManager是GroupCoordinator最重要的组成部分，其作用是管理group的元信息(状态、成员、提交的offset信息)以及作为coordinator的broker所分配到的分区信息，主要成员有4个： groupMetadataCache：存储group与GroupMetadata的cache loadingPartitions：”__consumer_offsets”中正在被当前coordinator加载的分区 ownedPartitions：”__consumer_offsets”中分配到当前coordinator的分区(即该broker是这些分区的leader) scheduler：删除过期offset以及group元数据的定时任务(执行间隔由offsets.retention.check.interval.ms参数控制，默认为10分钟) __consumer_offsets__consumer_offsets是用于存储消费者消费信息的topic，存储的消息由两部分组成 一部分是offset信息(kafka.coordinator.OffsetsMessageFormatter类型)的： [groupId,topic,partition]::[OffsetMetadata[offset,metadata],CommitTime ExprirationTime] 另一部分是group信息(kafka.coordinator.GroupMetadataMessageFormatter类型): groupId::[groupId,Some(consumer),groupState,Map(memberId -&gt; [memberId,clientId,clientHost,sessionTimeoutMs], ...-&gt;[]...)] group分配到哪个分区的策略在kafka cosumer中介绍过了。 作为一个特殊的topic，consumer_offsets也有replica的概念，并且其replica factor与其他topic保持一致。consumer_offsets上每个分区都对应一个leader，作为leader的broker上的GroupCoordinator会记录着分区上记录着的group以及offset信息。当leader(__consumer_offsets分布的leader)发生变化时，新的leader需要加载对应分区上的group以及offset信息。 server在处理LeaderAndIsrRequest时会对__consumer_offsets的分区做出入境 操作：def onLeadershipChange(updatedLeaders: Iterable[Partition], updatedFollowers: Iterable[Partition]) &#123; updatedLeaders.foreach &#123; partition =&gt; if (partition.topic == Topic.GroupMetadataTopicName) coordinator.handleGroupImmigration(partition.partitionId) &#125; updatedFollowers.foreach &#123; partition =&gt; if (partition.topic == Topic.GroupMetadataTopicName) coordinator.handleGroupEmigration(partition.partitionId) &#125;&#125; 小实验“G3”这个group根据hash映射到分区2上，当前的ISR为：Topic: __consumer_offsets Partition: 2 Leader: 1 Replicas: 1,3,2 Isr: 2,3,1 接下来，关闭broker1，导致broker3成为了新的leader。 broker3执行入境 操作，加载分区2上面的的offset以及group信息：[Group Metadata Manager]: Loading offsets and group metadata from [__consumer_offsets,2][Group Metadata Manager]: Loaded group metadata for group G3 with generation 1[Group Metadata Manager]: Loaded group metadata for group G3 with generation 2[Group Metadata Manager]: Loaded group metadata for group G3 with generation 3[Group Metadata Manager]: Loaded group metadata for group G3 with generation 4[Group Metadata Manager]: Loaded offset [OffsetMetadata[3448,NO_METADATA],CommitTime 1495503059311,ExpirationTime 1495506659311] for newOne-0.[Group Metadata Manager]: Loaded offset [OffsetMetadata[3441,NO_METADATA],CommitTime 1495503059311,ExpirationTime 1495506659311] for newOne-3.[Group Metadata Manager]: Loaded offset [OffsetMetadata[3257,NO_METADATA],CommitTime 1495503059311,ExpirationTime 1495506659311] for newOne-5.[Group Metadata Manager]: Loaded offset [OffsetMetadata[3382,NO_METADATA],CommitTime 1495503059311,ExpirationTime 1495506659311] for newOne-2.[Group Metadata Manager]: Loaded offset [OffsetMetadata[3397,NO_METADATA],CommitTime 1495503059311,ExpirationTime 1495506659311] for newOne-4.[Group Metadata Manager]: Loaded offset [OffsetMetadata[3163,NO_METADATA],CommitTime 1495503059311,ExpirationTime 1495506659311] for newOne-1.[GroupCoordinator 3]: Loading group metadata for G3 with generation 4[Group Metadata Manager]: Finished loading offsets from [__consumer_offsets,2] in 21 milliseconds. 在loadGroupsForPartition方法中通过使用Map确保加载每个group最新generation的信息 在执行入境操作之前，分区2被添加到loadingPartitions中，表示coordinator正在加载该分区里面的信息，这个阶段如果有groupId在loadingPartitions之内的消费请求进来，是无法响应的；处理完后，分区2被添加到ownedPartitions中。 保存group元数据方法定义如下：def prepareStoreGroup(group: GroupMetadata, groupAssignment: Map[String, Array[Byte]], responseCallback: Errors =&gt; Unit): Option[DelayedStore] groupAssignment是group中member的分区分配 返回值是DelayedStore，这并不是一个DO类型的延迟任务，只适用于存放消息的临时媒介，方便后续往replicas中写Log用的。 生成消息第一步是生成能往Log(确切的说是写入__consumer_offsets中该group对应的partition中)中写入的ByteBufferMessageSet(消息写入磁盘及备份实现分析),key为groupId,value为member以及sessionTimeout，即上面所说的group信息。 设置appendLog回调函数该回调函数作为参数传入到ReplicaManager.replicaMessages，对append操作的结果进行处理，最主要的就是状态的转换：case Errors.UNKNOWN_TOPIC_OR_PARTITION | Errors.NOT_ENOUGH_REPLICAS | Errors.NOT_ENOUGH_REPLICAS_AFTER_APPEND =&gt; Errors.GROUP_COORDINATOR_NOT_AVAILABLEcase Errors.NOT_LEADER_FOR_PARTITION =&gt; Errors.NOT_COORDINATOR_FOR_GROUPcase Errors.REQUEST_TIMED_OUT =&gt; Errors.REBALANCE_IN_PROGRESScase Errors.MESSAGE_TOO_LARGE | Errors.RECORD_LIST_TOO_LARGE | Errors.INVALID_FETCH_SIZE =&gt; Errors.UNKNOWN 执行storeGroup回调函数在doSyncGroup中定义了一个用于处理leader的SyncGroupRequest的回调函数：group synchronized &#123; if (group.is(AwaitingSync) &amp;&amp; generationId == group.generationId) &#123; if (error != Errors.NONE) &#123; resetAndPropagateAssignmentError(group, error) maybePrepareRebalance(group) &#125; else &#123; setAndPropagateAssignment(group, assignment) group.transitionTo(Stable) &#125; &#125;&#125; 因为在等待回调函数被执行的过程中，可能会有新的member加入，这样的话就无法保证group的状态以及generation不会变化的。 往replicas写group数据调用GroupMetadataManager的store方法，将DelayedStore中的messageSet以及回调函数传入到replicaManager的appendMessages方法中replicaManager.appendMessages( config.offsetCommitTimeoutMs.toLong, config.offsetCommitRequiredAcks, true, // allow appending to internal offset topic delayedStore.messageSet, delayedStore.callback) 保存offset commitprepareStoreOffsets方法与prepareStoreGroup基本相像：def prepareStoreOffsets(group: GroupMetadata, consumerId: String, generationId: Int, offsetMetadata: immutable.Map[TopicPartition, OffsetAndMetadata], responseCallback: immutable.Map[TopicPartition, Short] =&gt; Unit): Option[DelayedStore] 返回的依然是个DelayedStore。组装的MessageSet中,key为[groupId, topic, partition]，value为OffsetMetadata，写入的partition由groupId确定。 offsetCommit回调函数 GroupMetadata为offset commit创建了两个Cache：offsets以及pendingOffsetCommits，consumer提交的offset先存放到pending中，然后根据一定的状态来决定是否移到offsets中。 如果offsetCommit执行结束后group依旧存活那个根据是否有错误对cache执行不同的操作： 没有错误码，那么就将offset写入到offsets中，并从pendingOffsetCommits中移除； 有错误，那么仅仅将offset从pendingOffsetCommits中移除； offset以及group元数据的清理工作GroupMetadataManager在启动时会开启一个定时执行的清理线程：”delete-expired-group-metadata”，该线程的主要工作是清理__consumer_offsets中失效的offset以及可删除的group信息。 remove expire offset每个offset commit提交到server时，都会根据配置的保存时间来设置其失效时间，超过该时间的将会被清除掉。 首先，从cache中筛选出可清楚的offset集合：val expiredOffsets = offsets.filter &#123; case (topicPartition, offset) =&gt; offset.expireTimestamp &lt; startMs &amp;&amp; !pendingOffsetCommits.contains(topicPartition) &#125; offsets --= expiredOffsets.keySet expiredOffsets 执行完删除操作过后判断group是否可以判定为DEAD： group不包含member group的两个offsetCache都为空 立墓碑 当offset被移除或者group进入DEAD状态，都会在__consumer_offsets中留下一个墓碑。 对于group而言： 如果当前有member存在，那么其存在于__consumer_offsets中的数据是这样的： G6::[G6,Some(consumer),Stable,Map(client1-1ee1d482-c9fa-4617-860a-98d3a3d5a836 -&gt; [client1-1ee1d482-c9fa-4617-860a-98d3a3d5a836,client1,/10.45.48.129,120000])] 如果member为空，但是状态不是DEAD： G6::[G6,None,Empty,Map()] 如果group被该清理线程认为DEAD，该group信息不仅从groupMetadataCache中移除，还会在__cosnumer_offsets中留下一座墓碑： G6::NULL offset的立墓碑操作与group类似。 consumer与Coordinator的连接过程确定coordinator 在kafka cosumer中提到过consumer寻找coordinator的过程。 选择将哪个节点作为coordinator其实是由consumer client决定的，确切的说是向已连接的节点中随机选择一个最空闲的节点发送GroupCoordinatorRequest。(这里随机是指往一个空闲的随机broker发送请求，收到的response中分配到的coordinator是根据group找对__consumer_offsets对应分区的Leader)这里空闲的定义是：NetworkClient中处于inflight状态的请求数量少，下面是consumer寻找到coordinator的日志：[AbstractCoordinator] Sending coordinator request for group G6 to broker 10.45.4.10:9092[AbstractCoordinator] Received group coordinator response ClientResponse(receivedTimeMs=1495510047579, disconnected=false, request=ClientRequest(callback=..., request=RequestSend(header=&#123;api_key=10,api_version=0,correlation_id=0,client_id=client111&#125;, body=&#123;group_id=G6&#125;), createdTimeMs=1495510047472, sendTimeMs=1495510047577), responseBody=&#123;error_code=0,coordinator=&#123;node_id=1,host=10.45.4.9,port=9092&#125;&#125;) handleGroupCoordinatorRequestserver在接收到GroupCoordinatorRequest后： 根据groupId找到对应__consumer_offsets上的分区P 找到P对应的leader作为coordinator handleJoinGroup校验 简单校验： coordinator是否处于工作状态 groupId是否有效 coordinator是否负责该group sessionTimeoutMs是否合理 groupId是否在loadingPartitions中，如果在的话表明正在Rebalance中。 member校验：客户端ConsumerCoordinator发送的JoinGroupRequest 中的memberId永远都是空的，也就是说memberId是由server端进行设置的。如果Request中group是已知(存在于GroupMetadataManager.groupMetadataCache)的并且memberId非空，那么Server将拒绝这个请求。 响应请求 group有不同的状态，在不同的状态下有相应的响应joinGroupRequest方法 Deadgroup处于Dead状态表明该group中没有了成员，并且其GroupMetadata已被该coordinator移除,这个状态下对任何请求都是返回UnknownMemberIdException PreparingRebalance根据Request中memberId是否为空有两套处理逻辑： memberId为空：执行addMember操作 //新建memberId，格式为：clientId-UUID val memberId = clientId + &quot;-&quot; + group.generateMemberIdSuffixval member = new MemberMetadata(memberId, group.groupId, clientId, clientHost, rebalanceTimeoutMs, sessionTimeoutMs, protocolType, protocols)member.awaitingJoinCallback = callbackgroup.add(member.memberId, member)maybePrepareRebalance(group)member memberId不为空：执行updateMember操作 member.supportedProtocols = protocolsmember.awaitingJoinCallback = callbackmaybePrepareRebalance(group) 以上两个操作都不会触发PrepareRebalance操作，因为当前已经是PreparingReblance状态了。 AwaitingSync 这个状态表明coordinator已经发送了JoinGroupResponse了，正在等待leader发送分区分配的SyncGroupRequest. 这个时候如果收到一个memberId为空的JoinGroupRequest，表明group中有新的成员加入，除了要创建member信息添加到GroupMetadata中之外，还需要prepareRebalance，并将状态重新置为PreparingReblance 如果收到的memberId不为空，有两种情况： 该成员未收到之前发送过的JoinGroupResponse，这种情况就重新发送一个Response，leader和member分配不会改变的 这次的Request中改变了分区分配策略，因此需要执行updateMember操作，并且还需要执行PrepareRebalance操作将状态重新置为PreparingReblance。 Empty or Stable处理三种可能的joinGroup情形： 收到memberId为空的请求，group有新成员加入，执行addMember以及PrepareRebalce操作。 收到leader的joinGroup请求或者请求中的分配策略发生变化(何种场景下会leader会重发joinGroup请求嘞？分区变化时consumer是如何rejoin的) 其他情况(followers发送的没有内容变化的Join请求)说明followers可能没收到Response，因此重发Response。 handleSyncGroup在校验阶段如果发现该coordinator并不负责该group，则会反馈NotCoordinatorForGroupException。 能够正常响应SyncGroup请求的group状态为AwaitingSync和Stable，其中AwaitingSync状态下就是执行保存group数据 handleLeaveGroup主要有三步操作 1、从心跳DOP中移除心跳DOP(heartbeatPurgatory)中保存的是DelayedHeartbeat，该DO操作用于侦测member是否存活,成员变量包括group、member已经超时时间。当member要离开group时需要将该member对应的DO操作完成并移除掉。 2、从group中移除将member从其对应的GroupMetadata中的members中移除，然后根据当前group状态进行对应的处理： Stable or Empty：触发PrepareRebalance PreparingRebalance：complete掉joinPurgatory中该group的DJ操作 3、组装反馈信息其实consumer对LeaveGroupResponse不是很关心，因为不会重发。 handleFetchOffsetsconsumer是从coordinator维护的offset cache ：offsets中获取group已提交的offset信息的。 FetchRequest中包含group以及topic-partition信息，据此coordinator进行反馈： 如果group不存在 or group状态为DEAD，则返回的PartitionData中offset为-1(代表InvalidOffset) 如果未指定topic以及partition，那么就将offsets中所有的[topic-partition, commit offset]数据都反馈给consunmer 如果指定topic-partition，就将offsets中对应的数据反馈，找不到就反馈-1 Helper分区变化时consumer是如何rejoin的？消费者在长连接的时候，增加了分区的topic，client是如何感知到的呢，下面是实验过程记录： 10:33:08 开启consumer [AbstractCoordinator] Sending coordinator request for group G6 to broker 10.45.4.10:9092 (id: -2 rack: null)[AbstractCoordinator] Discovered coordinator 10.45.4.9:9092 (id: 2147483646 rack: null) for group G6.[ConsumerCoordinator] Revoking previously assigned partitions [] for group G6[ConcurrentMessageListenerContainer] partitions revoked:[][AbstractCoordinator] (Re-)joining group G6[AbstractCoordinator] Sending JoinGroup (&#123;group_id=G6,session_timeout=120000,member_id=,protocol_type=consumer,group_protocols=[&#123;protocol_name=range,protocol_metadata=java.nio.HeapByteBuffer[pos=0 lim=18 cap=18]&#125;]&#125;) to coordinator 10.45.4.9:9092 (id: 2147483646 rack: null)[AbstractCoordinator] Received successful join group response for group G6: [AbstractCoordinator] Successfully joined group G6 with generation 5[ConcurrentMessageListenerContainer] partitions assigned:[newOne-8, newOne-4, newOne-5, newOne-6, newOne-7, newOne-0, newOne-1, newOne-2, newOne-3] 10:34:17 controller检测到partitoin变化： [AddPartitionsListener on 2]: Partition modification triggered &#123;&quot;version&quot;:1,&quot;partitions&quot;:&#123;&quot;8&quot;:[2,1],&quot;4&quot;:[1,3],&quot;11&quot;:[2,1],&quot;9&quot;:[3,2],&quot;5&quot;:[2,1],&quot;10&quot;:[1,3],&quot;6&quot;:[3,2],&quot;1&quot;:[1,2],&quot;0&quot;:[3,1],&quot;2&quot;:[2,3],&quot;7&quot;:[1,3],&quot;3&quot;:[3,2]&#125;&#125; for path /brokers/topics/newOne (kafka.controller.PartitionStateMachine$PartitionModificationsListener) 10:38:10 client rejoin [ConsumerCoordinator] Revoking previously assigned partitions [newOne-8, newOne-4, newOne-5, newOne-6, newOne-7, newOne-0, newOne-1, newOne-2, newOne-3] for group G6[ConcurrentMessageListenerContainer] partitions revoked:[newOne-8, newOne-4, newOne-5, newOne-6, newOne-7, newOne-0, newOne-1, newOne-2, newOne-3][AbstractCoordinator] &quot;(Re-)joining group G6&quot;[AbstractCoordinator] Sending JoinGroup (&#123;group_id=G6,session_timeout=120000,member_id=client111-39aa3f5d-cdf2-492f-bf41-4affe1a00421,protocol_type=consumer,group_protocols=[&#123;protocol_name=range,protocol_metadata=java.nio.HeapByteBuffer[pos=0 lim=18 cap=18]&#125;]&#125;) to coordinator 10.45.4.9:9092 (id: 2147483646 rack: null)[AbstractCoordinator] Received successful join group response for group G6: &#123;error_code=0,generation_id=6,group_protocol=range,leader_id=client111-39aa3f5d-cdf2-492f-bf41-4affe1a00421,member_id=client111-39aa3f5d-cdf2-492f-bf41-4affe1a00421,members=[&#123;member_id=client111-39aa3f5d-cdf2-492f-bf41-4affe1a00421,member_metadata=java.nio.HeapByteBuffer[pos=0 lim=18 cap=18]&#125;]&#125;[AbstractCoordinator] Sending leader SyncGroup for group G6 to coordinator 10.45.4.9:9092 (id: 2147483646 rack: null): &#123;group_id=G6,generation_id=6,member_id=client111-39aa3f5d-cdf2-492f-bf41-4affe1a00421,group_assignment=[&#123;member_id=client111-39aa3f5d-cdf2-492f-bf41-4affe1a00421,member_assignment=java.nio.HeapByteBuffer[pos=0 lim=70 cap=70]&#125;]&#125;[AbstractCoordinator] Successfully joined group G6 with generation 6[ConsumerCoordinator] Setting newly assigned partitions [newOne-8, newOne-9, newOne-10, newOne-11, newOne-4, newOne-5, newOne-6, newOne-7, newOne-0, newOne-1, newOne-2, newOne-3] for group G6[ConcurrentMessageListenerContainer] partitions assigned:[newOne-8, newOne-9, newOne-10, newOne-11, newOne-4, newOne-5, newOne-6, newOne-7, newOne-0, newOne-1, newOne-2, newOne-3] 那么consumer到底是如何触发rejoin的呢，这个时间间隔有何讲究？ 一开始自己关注的点是rejoinNeeded什么时候被置为true 有三种情况下会被置为true： SyncGroupResponse中存在ERROR HeartbeatResponse中存在REBALANCE_IN_PROGRESS、ILLEGAL_GENERATION或UNKNOWN_MEMBER_ID的ERROR consumer leave group 然而从日志来看并没有出现错误，所以注意力转移到needRejoin方法中的其他判断条件：return subscriptions.partitionsAutoAssigned() &amp;&amp; (super.needRejoin() || subscriptions.partitionAssignmentNeeded()); partitionsAutoAssigned的条件是一直满足的，partitionAssignmentNeeded被置为true的场景有点多，排查起来比较费时费力。这时有个新的现象进入眼帘：经过多次试验后发现rejoin距离分区调整的时间间隔最长不超过5分钟！。而metadata.max.age.ms这个配置参数的默认值刚好是5分钟： 该配置项是client端强制刷新metadata的最长时间间隔。 因为kafka集群出现broker或者partition变化的时候是不会通知客户端的，因此客户端需要定期的去获取metadata的值。 客户端判断是否需要刷新metadata的方法：public synchronized long timeToNextUpdate(long nowMs) &#123; long timeToExpire = needUpdate ? 0 : Math.max(this.lastSuccessfulRefreshMs + this.metadataExpireMs - nowMs, 0); long timeToAllowUpdate = this.lastRefreshMs + this.refreshBackoffMs - nowMs; return Math.max(timeToExpire, timeToAllowUpdate);&#125; 其中metadataExpireMs就是5分钟【默认】。 ConsumerCoordinator为metadata添加了一个Listener监听其更新操作：private void addMetadataListener() &#123; this.metadata.addListener(new Metadata.Listener() &#123; @Override public void onMetadataUpdate(Cluster cluster) &#123; ... // check if there are any changes to the metadata which should trigger a rebalance if (subscriptions.partitionsAutoAssigned()) &#123; MetadataSnapshot snapshot = new MetadataSnapshot(subscriptions, cluster); if (!snapshot.equals(metadataSnapshot)) &#123; metadataSnapshot = snapshot; subscriptions.needReassignment(); &#125; &#125; &#125; &#125;);&#125; needReassignment()方法将needsPartitionAssignment置为true,这正是partitionAssignmentNeeded()方法所需要的。 how to prepare rebalance 在kafka cosumer中做个一个实验：consumer多次关闭重连后，partition将会在较长时间后才能分配到。GroupCoordinator做了什么才导致这样的现象发生嘞？ prepareReblance的代码不长，但是要搞懂到底做了些什么着实不易：private def prepareRebalance(group: GroupMetadata) &#123; // if any members are awaiting sync, cancel their request and have them rejoin if (group.is(AwaitingSync)) resetAndPropagateAssignmentError(group, Errors.REBALANCE_IN_PROGRESS) group.transitionTo(PreparingRebalance) info(&quot;Preparing to restabilize group %s with old generation %s&quot;.format(group.groupId, group.generationId)) val rebalanceTimeout = group.rebalanceTimeoutMs val delayedRebalance = new DelayedJoin(this, group, rebalanceTimeout) val groupKey = GroupKey(group.groupId) joinPurgatory.tryCompleteElseWatch(delayedRebalance, Seq(groupKey))&#125; DelayedOperation And DelayedOperationPurgatorypurgatory wiki DelayedJoin(简称DJ)是DelayedOperation(简称DO)的子类，DelayedOperationPurgatory(简称DOP)用于记录DO，并将超时的DO执行expired操作? DO用于执行延迟任务，参数只有一个超时时间，目前已有的实现类有： 比如DelayedFetch的操作允许Fetch等待一定数量的消息或者达到超时时间后再返回。 当DO完成给定的操作后，会调用onComplete方法(该方法需要子类实现)并且只会被调用一次, isComplete方法将返回true(通过原子变量AtomicBoolean实现)； forceComplete和tryComplete方法等能触发onComplete，其中前者已经在DO中实现了：def forceComplete(): Boolean = &#123; if (completed.compareAndSet(false, true)) &#123; // cancel the timeout timer cancel() onComplete() true &#125; else &#123; false &#125;&#125; 该方法将原子变量强行换成true(如果当前为false的话)，然后调用onComplete操作；后者需要子类实现：在判断是否达到complete条件后再调用forceComplete。 safeTryComplete是TryComplete的线程安全版： def safeTryComplete(): Boolean = &#123; synchronized &#123; tryComplete() &#125;&#125; 如果DO超时，将调用onExpiration操作(0.10.1.1版本中，DJ仍未实现该方法) WatchersDOP形象的定义了Watchers这个类用于存放和“观察”DO，使用到的数据结构是ConcurrentLinkedQueue。 watch：该方法将DO添加到队列中 tryComplteWatched：遍历队列，将已完成的DO从队列中移除，调用未完成DO的safeTryComplte方法，并记录在该方法中完成的DO数量。 purgeCompleted：该方法只是将已完成的移除掉，并返回移除的数量。 每个Watchers都与一些key关联(HashMap)，定义为watchersForKey Key的类型没有限制， 当key对应的DO全部完成后，key以及对应的Watchers一起从Map中移除。 其他参数及属性 timeoutTimer brokerId purgeInterval：清理基准线，当DOP中已完成的DO数量达到该基准线后开始清理操作 reaperenbaled：是否允许清除DO watchersForKey：存放watcher与对应的key expirationReaper：超时DO清道夫 tryCompleteElseWatch该方法将一个DO塞进Watchers中并与多个Key进行关联。如果每次与Key进行关联时都执行一次tryComplete操作成本很大。kafka选择了一个折中的策略，保证在该方法内最多调用两次tryComplete方法： 执行第一次tryComplete操作，成功就返回 遍历keys，如果DO未完成就将key与Watchers进行绑定，添加到watchersForKey 执行第二次tryComplete，成功就返回 依然未成功的话就添加到timeoutTimer中(进入这里面的DO将怎么处理？怎么才能再次触发onComplete操作呢？) 放到Timer中的DO在超时的时候会执行TimerTask#run()方法 DelayedOperation基础了TimerTask类，覆盖了父类的run方法： override def run(): Unit = &#123; if (forceComplete()) onExpiration()&#125; DelayedJoinGroupCoordinator中实现了DJ作为DO的各个方法，在分析这些方法前需要关注的是GroupMetadata 与 MemberMetadata的两个属性： notYetRejoinedMembers AND awaitingJoinCallback awaitingJoinCallback是Mebmer的属性，初始为null;当member所在的group处于PreparingReblance状态下，member向coordinator发送了JoinGroup请求，那么该字段用于存放将JoinGroupResult反馈的回调方法，在重平衡结束后或者coordinator执行出境操作等会将该字段重新置为Null notYetRejoinedMembers存放该group中没有awaitingJoinCallback的member，在Rebalance期间，该集合中存储的是那些没有发送JoinGroup请求的member。 tryComplete如果group中所有的成员都发送了JoinGroupRequest 就调用forceComplete方法(DO中的方法)：def tryCompleteJoin(group: GroupMetadata, forceComplete: () =&gt; Boolean) = &#123; group synchronized &#123; if (group.notYetRejoinedMembers.isEmpty) forceComplete() else false &#125;&#125; 留个问题 如果某个member迟迟不发送JoinGroup请求的话，那总不能永久等待吧？member在什么情况下会被移出group呢？(关键点在于DelayedHeartbeat的onExpireHeartbeat方法) onExpireHeartbeat如果coordinator听不到member的心跳：member.latestHeartbeat + member.sessionTimeoutMs &gt; heartbeatDeadline heartbeat的超时时间由consumer的session.timeout.ms控制【默认为100s】那么就会将member从group中移除：private def onMemberFailure(group: GroupMetadata, member: MemberMetadata) &#123; trace(\"Member %s in group %s has failed\".format(member.memberId, group.groupId)) group.remove(member.memberId) group.currentState match &#123; case Dead | Empty =&gt; case Stable | AwaitingSync =&gt; maybePrepareRebalance(group) case PreparingRebalance =&gt; joinPurgatory.checkAndComplete(GroupKey(group.groupId)) &#125;&#125; 如果当前group处于PreparingRebalance状态，那么将会将查下是否可以complete join操作。那么前面两个问题已经明朗了： 添加到DOP的timeoutTimer中的DO只是放入一个定时器内，超时后移除，DO能否在超时前执行onComplete操作完全靠外部触发； 如果某个group存在多个member，如果其中存在member非正常退出(即没有执行unsubscribe操作)，那么coordinator必须依赖心跳超时来检查该member是否dead，在此期间内的joinGroup请求无法立即得到响应。 onCompleteJoin疑惑 该方法的第一步看不懂：// remove any members who haven't joined the group yetgroup.notYetRejoinedMembers.foreach &#123; failedMember =&gt; group.remove(failedMember.memberId) // TODO: cut the socket connection to the client&#125; 能够执行onCompleteJoin说明notYetRejoinedMembers已经是空的了，这里的移除操作感觉多余了？？？？ JoinGroupResult：val joinResult = JoinGroupResult( members=if (member.memberId == group.leaderId) &#123; group.currentMemberMetadata &#125; else &#123; Map.empty &#125;, memberId=member.memberId, generationId=group.generationId, subProtocol=group.protocol, leaderId=group.leaderId, errorCode=Errors.NONE.code) group的leaderId采取先来后到的原则，新来的memberId作为leaderId。 对于非正常重启一个consumer所遇到的长时间等待可以用下图加深理解：","categories":[],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://yoursite.com/tags/Kafka/"}]},{"title":"test_blog","slug":"test-blog","date":"2018-04-04T03:22:14.000Z","updated":"2018-04-04T07:28:05.135Z","comments":true,"path":"2018/04/04/test-blog/","link":"","permalink":"http://yoursite.com/2018/04/04/test-blog/","excerpt":"","text":"this is titlethis is the second title//this is codepublic static void main(String[] args) &#123; System.out.println(\"hello world\");&#125;","categories":[],"tags":[{"name":"test","slug":"test","permalink":"http://yoursite.com/tags/test/"}]},{"title":"Hello World","slug":"hello-world","date":"2018-04-04T02:16:19.237Z","updated":"2018-04-04T02:16:19.239Z","comments":true,"path":"2018/04/04/hello-world/","link":"","permalink":"http://yoursite.com/2018/04/04/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new \"My New Post\" More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}